{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\lucas\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4) (2.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\lucas\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\lucas\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.18.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\lucas\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.21.1)\n",
      "Requirement already satisfied: Levenshtein==0.21.1 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-Levenshtein) (0.21.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Levenshtein==0.21.1->python-Levenshtein) (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\lucas\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip3 install requests\n",
    "!pip3 install beautifulsoup4\n",
    "!pip3 install pandas\n",
    "!pip3 install fuzzywuzzy\n",
    "!pip3 install python-Levenshtein\n",
    "\n",
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from urllib.parse import quote\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from difflib import get_close_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marca</th>\n",
       "      <th>tipo producto</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Engine</th>\n",
       "      <th>Drive</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>changan</td>\n",
       "      <td>camioneta</td>\n",
       "      <td>hunter 1.9l comfort</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>changan</td>\n",
       "      <td>camioneta</td>\n",
       "      <td>hunter 1.9l comfort</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4X4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>changan</td>\n",
       "      <td>camioneta</td>\n",
       "      <td>hunter 1.9l elite</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4X4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>changan</td>\n",
       "      <td>camioneta</td>\n",
       "      <td>hunter 1.9l luxury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>changan</td>\n",
       "      <td>camioneta</td>\n",
       "      <td>hunter 1.9l luxury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4X4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     marca tipo producto           Model Name  Engine Drive Transmission  Year\n",
       "0  changan     camioneta  hunter 1.9l comfort     NaN   NaN          NaN   NaN\n",
       "1  changan     camioneta  hunter 1.9l comfort     NaN   4X4          NaN   NaN\n",
       "2  changan     camioneta    hunter 1.9l elite     NaN   4X4          NaN   NaN\n",
       "3  changan     camioneta   hunter 1.9l luxury     NaN   NaN          NaN   NaN\n",
       "4  changan     camioneta   hunter 1.9l luxury     NaN   4X4          NaN   NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('csvs/parsed_output.csv')\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# Define a helper function to handle retries\n",
    "def make_request_with_retry(url, retries=10, delay=2):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            return response\n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            if response.status_code == 500:\n",
    "                if attempt < retries - 1:\n",
    "                    print(f\"Server error (500) encountered at {url}. Waiting {delay} second(s) before retrying...\")\n",
    "                    time.sleep(delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Failed to access {url} after {retries} attempts: {err}\")\n",
    "                    return None\n",
    "            else:\n",
    "                print(f\"Failed to access {url}: {err}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while accessing {url}: {e}\")\n",
    "            return None\n",
    "\n",
    "def normalize_string(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[^\\w\\s]', '', s)\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    return s.strip()\n",
    "\n",
    "def find_base_model_and_version(model_name):\n",
    "    descriptors = ['advance', '3', 'row', 'e-power', 'exclusive', 'sense', 'le', 'xle', 'limited',\n",
    "                   'luxury', 'pro', 'elite', 'glx', 'at', 'mt', '4x2', '4x4', 'awd', '2wd', 'dct',\n",
    "                   'cvt', 'td', 'tdi', 'tdci', 's', 'se', 'lt', 'ltz', 'ls', 'premium', 'plus',\n",
    "                   'xt', 'xtronic', 'sunroof', 'diesel', 'gasolina', 'elegance', 'hibrido', 'hev',\n",
    "                   'hybrid', 'comfort', 'deluxe', 'gt', 'sport', 'xl', 'xlt', 'xse', 'p4x']\n",
    "    words = normalize_string(model_name).split()\n",
    "    base_model_words = [word for word in words if word not in descriptors]\n",
    "    base_model_name = ' '.join(base_model_words)\n",
    "    version_words = [word for word in words if word in descriptors]\n",
    "    version_name = ' '.join(version_words)\n",
    "    return base_model_name.strip(), version_name.strip()\n",
    "\n",
    "def get_best_match(query, choices, cutoff=0.6):\n",
    "    matches = get_close_matches(query, choices, n=1, cutoff=cutoff)\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "    else:\n",
    "        # Attempt substring matching\n",
    "        for choice in choices:\n",
    "            if query in choice or choice in query:\n",
    "                return choice\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardamos el nombre de las marcas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('csvs/parsed_output.csv')\n",
    "\n",
    "# Extract the unique 'marca's\n",
    "unique_marcas = df['marca'].drop_duplicates()\n",
    "\n",
    "# Create a new DataFrame with the unique 'MARCA's\n",
    "unique_marcas_df = pd.DataFrame(unique_marcas, columns=['macra'])\n",
    "\n",
    "# Save the unique 'MARCA's to a new CSV file\n",
    "unique_marcas_df.to_csv('unique_marcas.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando marca: changan\n",
      "Procesando marca: chevrolet\n",
      "Procesando marca: dfsk\n",
      "Procesando marca: dongfeng\n",
      "Procesando marca: fiat\n",
      "Procesando marca: ford\n",
      "Procesando marca: foton\n",
      "Procesando marca: great wall\n",
      "Procesando marca: honda\n",
      "Procesando marca: jac\n",
      "Procesando marca: jmc\n",
      "Procesando marca: karry\n",
      "Procesando marca: kia\n",
      "Procesando marca: mahindra\n",
      "Procesando marca: maxus\n",
      "Procesando marca: mazda\n",
      "Procesando marca: mitsubishi\n",
      "Procesando marca: nissan\n",
      "Procesando marca: peugeot\n",
      "Procesando marca: ram\n",
      "Procesando marca: renault\n",
      "Procesando marca: ssangyong\n",
      "Procesando marca: suzuki\n",
      "Procesando marca: toyota\n",
      "Procesando marca: volkswagen\n",
      "Procesando marca: zna\n",
      "Procesando marca: baic\n",
      "Procesando marca: byd\n",
      "Procesando marca: chery\n",
      "Procesando marca: citroen\n",
      "Procesando marca: hyundai\n",
      "Procesando marca: mg\n",
      "Procesando marca: exeed\n",
      "Procesando marca: gac\n",
      "Procesando marca: haval\n",
      "Procesando marca: jeep\n",
      "Procesando marca: jetour\n",
      "Procesando marca: kaiyi\n",
      "Procesando marca: opel\n",
      "Procesando marca: subaru\n",
      "Procesando marca: farizon\n",
      "Failed to access https://www.autocosmos.cl/catalogo/vigente/farizon: 404 Client Error: Not Found for url: https://www.autocosmos.cl/catalogo/vigente/farizon\n",
      "Procesando marca: kyc\n",
      "     MARCA                                         Model Name  \\\n",
      "0  Changan  Changan Alsvin nuevos, precios del catálogo y ...   \n",
      "1  Changan  Changan CS15 nuevos, precios del catálogo y co...   \n",
      "2  Changan  Changan CS35 Plus  nuevos, precios del catálog...   \n",
      "3  Changan  Changan CS55 nuevos, precios del catálogo y co...   \n",
      "4  Changan  Changan CS55 Plus nuevos, precios del catálogo...   \n",
      "\n",
      "                                           Model URL  \n",
      "0  https://www.autocosmos.cl/catalogo/vigente/cha...  \n",
      "1  https://www.autocosmos.cl/catalogo/vigente/cha...  \n",
      "2  https://www.autocosmos.cl/catalogo/vigente/cha...  \n",
      "3  https://www.autocosmos.cl/catalogo/vigente/cha...  \n",
      "4  https://www.autocosmos.cl/catalogo/vigente/cha...  \n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo unique_marcas.csv\n",
    "marcas_df = pd.read_csv('csvs/unique_marca_modelo_by_tipo_producto.csv')\n",
    "marcas_df = marcas_df[['marca']].drop_duplicates()\n",
    "\n",
    "# Lista para almacenar los datos\n",
    "models_data = []\n",
    "\n",
    "# Iterar sobre cada marca\n",
    "for index, row in marcas_df.iterrows():\n",
    "    manufacturer = str(row['marca']).lower()\n",
    "    print(f\"Procesando marca: {manufacturer}\")\n",
    "    \n",
    "    # Construir la URL\n",
    "    base_url = 'https://www.autocosmos.cl/catalogo/vigente/'\n",
    "    manufacturer_normalized = normalize_string(manufacturer).replace(' ', '-')\n",
    "    manufacturer_url = base_url + manufacturer_normalized\n",
    "    \n",
    "    # Realizar la solicitud HTTP con reintentos\n",
    "    response = make_request_with_retry(manufacturer_url)\n",
    "    if response is None:\n",
    "        continue  # Saltar a la siguiente iteración si la solicitud falló\n",
    "    \n",
    "    # Analizar la página de la marca\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Encontrar la sección de modelos\n",
    "    models_section = soup.find('section', class_='section m-brand')\n",
    "    if models_section:\n",
    "        model_links = models_section.find_all('a', href=True)\n",
    "    else:\n",
    "        print(f\"No se encontraron modelos para {manufacturer}\")\n",
    "        continue\n",
    "    \n",
    "    # Extraer nombres de modelos y URLs\n",
    "    for link in model_links:\n",
    "        model_name = link.get('title', '').strip()\n",
    "        model_href = link['href']\n",
    "        # Construir la URL completa del modelo\n",
    "        full_model_url = 'https://www.autocosmos.cl' + model_href\n",
    "        \n",
    "        # Almacenar los datos\n",
    "        models_data.append({\n",
    "            'MARCA': manufacturer.title(),\n",
    "            'Model Name': model_name,\n",
    "            'Model URL': full_model_url\n",
    "        })\n",
    "\n",
    "# Convertir la lista a un DataFrame\n",
    "models_df = pd.DataFrame(models_data)\n",
    "\n",
    "# Guardar en un archivo CSV\n",
    "models_df.to_csv('csvs/models_by_marcas.csv', index=False)\n",
    "\n",
    "# Mostrar una muestra de los datos\n",
    "print(models_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csvs/models_by_marcas.csv')\n",
    "\n",
    "# Function to clean the Model Name\n",
    "def clean_model_name(row):\n",
    "    marca = normalize_string(row['MARCA'].strip())\n",
    "    model_name = row['Model Name'].strip()\n",
    "    model_name_normalized = normalize_string(model_name)\n",
    "    \n",
    "    # Remove the manufacturer name from the model name\n",
    "    pattern_marca = re.compile(r'\\b' + re.escape(marca) + r'\\b', re.IGNORECASE)\n",
    "    model_name_cleaned = pattern_marca.sub('', model_name_normalized).strip()\n",
    "    \n",
    "    # Remove the phrase 'nuevos, precios del catálogo y cotizaciones.'\n",
    "    phrase_to_remove = 'nuevos, precios del catalogo y cotizaciones.'\n",
    "    model_name_cleaned = model_name_cleaned.replace(phrase_to_remove, '').strip()\n",
    "    \n",
    "    pattern_marca_original = re.compile(r'\\b' + re.escape(row['MARCA']) + r'\\b', re.IGNORECASE)\n",
    "    model_name_original_cleaned = pattern_marca_original.sub('', row['Model Name']).strip()\n",
    "    # Then remove the phrase (case-insensitive)\n",
    "    pattern_phrase = re.compile(re.escape('nuevos, precios del catálogo y cotizaciones.'), re.IGNORECASE)\n",
    "    model_name_original_cleaned = pattern_phrase.sub('', model_name_original_cleaned).strip()\n",
    "    \n",
    "    return model_name_original_cleaned\n",
    "\n",
    "# Apply the cleaning function to the 'Model Name' column\n",
    "df['Model Name'] = df.apply(clean_model_name, axis=1)\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV\n",
    "df.to_csv('models_by_marcas_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        marca tipo producto model name  engine drive transmission    year  \\\n",
      "1532  farizon        furgon        v6e     NaN   NaN           AT  2024.0   \n",
      "\n",
      "     model name simplified marca simplified model url  \n",
      "1532                   v6e          farizon      None  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Load CSV files\n",
    "df1 = pd.read_csv('csvs/models_by_marcas_cleaned.csv')\n",
    "df2 = pd.read_csv('csvs/parsed_output.csv')\n",
    "\n",
    "# Standardize column names to lowercase\n",
    "df1.columns = df1.columns.str.lower().str.strip()\n",
    "df2.columns = df2.columns.str.lower().str.strip()\n",
    "\n",
    "# Ensure correct data types and fill missing values\n",
    "columns_to_normalize = ['marca', 'model name']\n",
    "for col in columns_to_normalize:\n",
    "    df1[col] = df1[col].astype(str).fillna('')\n",
    "    df2[col] = df2[col].astype(str).fillna('')\n",
    "\n",
    "# Function to normalize strings\n",
    "def normalize_string(s):\n",
    "    s = str(s).lower()\n",
    "    s = ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "    s = re.sub(r'[^\\w\\s]', '', s)  # Remove punctuation\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()  # Remove extra spaces\n",
    "    return s\n",
    "\n",
    "# Normalize 'model name' and 'marca'\n",
    "for df in [df1, df2]:\n",
    "    df['model name simplified'] = df['model name'].apply(normalize_string)\n",
    "    df['marca simplified'] = df['marca'].apply(normalize_string)\n",
    "\n",
    "# Function to match model names\n",
    "def match_model(row):\n",
    "    marca = row['marca simplified']\n",
    "    model_name = row['model name simplified']\n",
    "    df1_marca = df1[df1['marca simplified'] == marca]\n",
    "    if df1_marca.empty:\n",
    "        return None\n",
    "\n",
    "    # Try exact match first\n",
    "    exact_matches = df1_marca[df1_marca['model name simplified'] == model_name]\n",
    "    if not exact_matches.empty:\n",
    "        return exact_matches.iloc[0]['model url']\n",
    "\n",
    "    # Try substring match\n",
    "    substring_matches = df1_marca[df1_marca['model name simplified'].apply(lambda x: x in model_name or model_name in x)]\n",
    "    if not substring_matches.empty:\n",
    "        return substring_matches.iloc[0]['model url']\n",
    "\n",
    "    # Try fuzzy matching\n",
    "    df1_marca['score'] = df1_marca['model name simplified'].apply(lambda x: fuzz.token_set_ratio(model_name, x))\n",
    "    best_match = df1_marca.loc[df1_marca['score'].idxmax()]\n",
    "    if best_match['score'] >= 80:  # Adjusted threshold\n",
    "        return best_match['model url']\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def match_model_2(row):\n",
    "    marca = row['marca simplified']\n",
    "    model_name = row['model name simplified']\n",
    "    \n",
    "    # Filter df1 by the same brand\n",
    "    df1_marca = df1[df1['marca simplified'] == marca]\n",
    "    if df1_marca.empty:\n",
    "        return None\n",
    "\n",
    "    # Compute fuzzy match scores for all models in the filtered df1\n",
    "    df1_marca['score'] = df1_marca['model name simplified'].apply(lambda x: fuzz.token_set_ratio(model_name, x))\n",
    "    \n",
    "    # Select the top-scoring match\n",
    "    best_match = df1_marca.loc[df1_marca['score'].idxmax()]\n",
    "    return best_match['model url']\n",
    "\n",
    "\n",
    "# Apply the matching function to df2\n",
    "# df2['model url'] = df2.apply(match_model, axis=1)\n",
    "\n",
    "# Save the updated df2\n",
    "# df2.to_csv('csvs/parsed_output_with_urls.csv', index=False)\n",
    "\n",
    "# Apply the matching function to df2\n",
    "df2['model url'] = df2.apply(match_model_2, axis=1)\n",
    "\n",
    "# Save the updated df2\n",
    "df2.to_csv('csvs/parsed_output_with_urls_2.csv', index=False)\n",
    "\n",
    "# Print the unmatched models\n",
    "unmatched = df2[df2['model url'].isnull()]\n",
    "print(unmatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Model URLs have been saved to 'unique_model_urls.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file with Model URLs\n",
    "df = pd.read_csv('csvs/parsed_output_with_urls_2.csv')\n",
    "\n",
    "# Ensure 'Model URL' column is of string type and fill NaNs\n",
    "df['model url'] = df['model url'].astype(str).fillna('')\n",
    "\n",
    "# Drop empty URLs and get unique URLs\n",
    "unique_urls = df['model url'][df['model url'] != ''].unique()\n",
    "\n",
    "# Create a DataFrame from the unique URLs\n",
    "df_unique_urls = pd.DataFrame(unique_urls, columns=['model url'])\n",
    "\n",
    "# Save the unique URLs to a new CSV file\n",
    "df_unique_urls.to_csv('csvs/unique_model_urls.csv', index=False)\n",
    "\n",
    "print(\"Unique Model URLs have been saved to 'unique_model_urls.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/changan/hunter\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/changan/md201-pick-up\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/changan/md201-cargo-box\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/changan/x7-plus\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/changan/ms201-pick-up\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/chevrolet/colorado\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/chevrolet/montana\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/chevrolet/silverado\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/dfsk/d1\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/dongfeng/aeolus-gs-cross\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/fiat/ducato\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ford/maverick\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ford/ranger\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/foton/g7\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/great-wall/poer\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/great-wall/wingle-7-gasolina\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/honda/pilot\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jac/t6-diesel\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jac/t8\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jac/x200\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jmc/grand-avenue\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jmc/vigus-ev\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jmc/vigus-plus\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jmc/vigus-work\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jmc/vigus-pro\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/karry/q52\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/kia/frontier\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mahindra/pik-up\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/maxus/g-10-cargo\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/maxus/deliver-9-cargo\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/maxus/edeliver-3\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/maxus/deliver-9-chasis\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/maxus/t60\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/maxus/t90\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mazda/bt-50\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mitsubishi/l200-dakar\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mitsubishi/l-200\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/nissan/navara\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/peugeot/boxer\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/peugeot/landtrek\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ram/v700-rapid\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ram/v700-city\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ram/rampage\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ram/700\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ram/1000\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/renault/oroch\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ssangyong/musso\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/suzuki/carry\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/toyota/hilux\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/toyota/fortuner\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/volkswagen/saveiro-cross\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/volkswagen/jetta-gli\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/volkswagen/saveiro\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/zna/df6\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/baic/eu5\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/byd/han-ev\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/byd/song-plus-dm-i\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/byd/seal\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/changan/alsvin\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/chery/tiggo-3-pro\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/chevrolet/onix\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/chevrolet/sail\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/citroen/c-elysee\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/citroen/c3-bluehdi\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/fiat/mobi\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/fiat/fastback\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/honda/city\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/honda/civic\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/hyundai/grand-i10-sedan\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/hyundai/grand-i10\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/hyundai/palisade\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/kia/ev6\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/kia/soluto\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mazda/2\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mazda/3\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mazda/6\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mg/3\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mg/5\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mg/6\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mg/gt\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/nissan/leaf\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/nissan/sentra\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/nissan/versa\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/peugeot/3008-hybrid4\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/peugeot/partner\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/peugeot/e-partner\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/renault/kwid-e-tech\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/renault/koleos\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/suzuki/dzire\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/toyota/c-hr\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/toyota/corolla-cross\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/toyota/rush\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/toyota/yaris\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/volkswagen/virtus\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/baic/bj40-plus\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/baic/x35\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/baic/x55\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/byd/song-plus\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/byd/yuan-plus-ev\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/changan/cs15\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/changan/cs35-plus\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/changan/cs55\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/changan/star-truck-plus\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/chery/tiggo-8\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/chery/tiggo-2-pro-max\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/chevrolet/blazer\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/chevrolet/bolt\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/chevrolet/captiva-xl\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/chevrolet/groove\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/chevrolet/suburban\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/chevrolet/tahoe\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/chevrolet/traverse\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/chevrolet/onix-rs\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/chevrolet/tracker\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/citroen/berlingo\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/citroen/c5-aircross\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/dfsk/500-active\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/dfsk/560\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/dfsk/600\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/exeed/lx\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/exeed/txl\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/fiat/pulse\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ford/explorer-st\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ford/bronco-sport\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ford/f-150-raptor\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ford/transit-chasis\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ford/transit-custom\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ford/escape\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ford/expedition\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ford/explorer\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ford/territory\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/gac/emkoo\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/gac/emzoom\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/gac/gs3-power\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/gac/gs4-power\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/gac/gs8\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/haval/h6\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/haval/jolion\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/honda/cr-v\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/honda/hr-v\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/honda/wr-v\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/hyundai/creta\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/hyundai/ioniq-5\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/hyundai/kona\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/hyundai/santa-fe\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/hyundai/tucson\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/hyundai/venue\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jac/js2\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jac/js3\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jac/js4\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jac/js6\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jac/js8\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jac/sunray-pasajeros\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jac/refine-cargo-ev\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jeep/compass\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jeep/commander\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jeep/grand-cherokee\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jeep/grand-cherokee-l\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jeep/renegade\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jeep/wrangler\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jetour/dashing\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jetour/x70\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jetour/x90-plus\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/kaiyi/x3\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/kaiyi/x3-pro\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/kia/carens\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/kia/niro-hibrido\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/kia/ev9\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/kia/seltos\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/kia/sonet\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/kia/sorento\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/kia/sportage\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mahindra/xuv-300\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/maxus/d60\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/maxus/d90\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/maxus/euniq-6\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/maxus/g90\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mazda/cx-3\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mazda/cx-30\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mazda/cx-5\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mazda/cx-9\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mg/hs\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mg/marvel-r\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mg/zs\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mg/one\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mg/rx5\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mg/zx\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mitsubishi/asx\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mitsubishi/eclipse-cross\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mitsubishi/montero-sport\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mitsubishi/outlander\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/mitsubishi/xpander\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/nissan/kicks\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/nissan/pathfinder\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/nissan/qashqai\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/nissan/x-trail\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/opel/crossland\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/opel/grandland\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/opel/mokka\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/peugeot/traveller\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/peugeot/rifter\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/renault/arkana\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/renault/duster\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ssangyong/korando\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ssangyong/rexton\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ssangyong/tivoli\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ssangyong/torres\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/subaru/crosstrek\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/suzuki/jimny\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/suzuki/s-cross\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/suzuki/grand-vitara\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/suzuki/xl7\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/toyota/4runner\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/toyota/land-cruiser-prado\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/toyota/raize\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/toyota/rav4--hibrido\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/toyota/rav4\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/volkswagen/t-cross\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/volkswagen/tiguan\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/citroen/jumper\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/citroen/spacetourer\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ford/transit-bus\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/hyundai/staria-furgon\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/hyundai/santa-fe-hibrida\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/hyundai/staria\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/jac/refine-cargo\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/maxus/g-10-ejecutiva\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/maxus/mifa-9\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/maxus/t90-ev\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/nissan/x-trail-e-power\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/toyota/hiace-pasajeros\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/toyota/hiace-furgon\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/toyota/yaris-gr\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/changan/m201-furgon\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/chevrolet/n400-max\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/citroen/jumpy\n",
      "Scraping URL: nan\n",
      "An error occurred for nan: Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ford/transit-furgon\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/kyc/gran-mamut-cargo-box\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/maxus/edeliver-9\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/opel/combo\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/peugeot/expert\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/ram/v1000\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/fiat/500e\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/opel/corsa\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/peugeot/308\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/renault/kwid\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/suzuki/alto\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/suzuki/baleno\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/suzuki/s-presso\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/suzuki/swift\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/toyota/fortuner-gr-s\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/toyota/hilux-gr-s\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/toyota/yaris-cross\n",
      "Scraping URL: https://www.autocosmos.cl/catalogo/vigente/volkswagen/polo\n",
      "Scraping completed. Data saved to 'model_versions.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Read the unique URLs\n",
    "df_urls = pd.read_csv('csvs/unique_model_urls.csv')\n",
    "\n",
    "# Initialize a list to hold scraped data\n",
    "scraped_data = []\n",
    "\n",
    "max_retries = 10  # Maximum number of retries for 500 errors\n",
    "\n",
    "for index, row in df_urls.iterrows():\n",
    "    url = row['model url']\n",
    "    print(f\"Scraping URL: {url}\")\n",
    "    \n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            response = requests.get(url, timeout=None)\n",
    "            if response.status_code == 500:\n",
    "                print(f\"Received 500 error on {url}, retrying... ({attempt + 1}/{max_retries})\")\n",
    "                attempt += 1\n",
    "                time.sleep(1)  # Sleep before retrying\n",
    "                continue\n",
    "            else:\n",
    "                response.raise_for_status()\n",
    "                break  # Successful response, exit retry loop\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"An error occurred for {url}: {e}\")\n",
    "            break  # Break on any request exception other than 500 error\n",
    "    else:\n",
    "        # This else executes if the loop completes without a break (after max retries)\n",
    "        print(f\"Failed to retrieve {url} after {max_retries} attempts.\")\n",
    "        continue\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find the table containing the versions\n",
    "    version_table = soup.find('table', class_='table')\n",
    "    if not version_table:\n",
    "        print(f\"No version table found at {url}\")\n",
    "        continue\n",
    "    \n",
    "    # Find all rows in the table body\n",
    "    tbody = version_table.find('tbody')\n",
    "    if not tbody:\n",
    "        print(f\"No table body found at {url}\")\n",
    "        continue\n",
    "\n",
    "    rows = tbody.find_all('tr', itemprop='offers')\n",
    "    versions = []\n",
    "    for row in rows:\n",
    "        # Find the meta tag with itemprop=\"name\"\n",
    "        meta_name = row.find('meta', itemprop='name')\n",
    "        a_tag = row.find('a', itemprop='url')\n",
    "        href = a_tag.get('href', '') if a_tag else ''\n",
    "        if meta_name:\n",
    "            version_name = meta_name.get('content', '')\n",
    "            version_name = re.sub(r'\\s*\\(\\d{4}\\)\\s*', '', version_name)\n",
    "            full_url = \"https://www.autocosmos.cl\" + href\n",
    "            versions.append([version_name, full_url])\n",
    "    \n",
    "    scraped_data.append({\n",
    "        'model url': url,\n",
    "        'versions': versions\n",
    "    })\n",
    "    \n",
    "    time.sleep(3)\n",
    "\n",
    "# Save the scraped data to a CSV\n",
    "df_scraped = pd.DataFrame(scraped_data)\n",
    "\n",
    "# Convert 'Versions' from list of lists to a string\n",
    "def versions_to_string(versions_list):\n",
    "    return '; '.join([f\"{v[0]}: {v[1]}\" for v in versions_list])\n",
    "\n",
    "df_scraped['versions'] = df_scraped['versions'].apply(versions_to_string)\n",
    "\n",
    "df_scraped.to_csv('csvs/model_versions.csv', index=False)\n",
    "\n",
    "print(\"Scraping completed. Data saved to 'model_versions.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching completed. Data saved to 'matched_versions.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Read the CSV files\n",
    "df_parsed = pd.read_csv('csvs/parsed_output_with_urls_2.csv')\n",
    "df_versions = pd.read_csv('csvs/model_versions.csv')\n",
    "\n",
    "# Function to parse the 'Versions' column\n",
    "def parse_versions_string(versions_str):\n",
    "    version_list = []\n",
    "    if pd.isna(versions_str) or versions_str.strip() == '':\n",
    "        return version_list\n",
    "    versions = versions_str.split(';')\n",
    "    for v in versions:\n",
    "        v = v.strip()\n",
    "        if not v:\n",
    "            continue\n",
    "        if ':' in v:\n",
    "            name, url = v.split(':', 1)\n",
    "            version_list.append([name.strip(), url.strip()])\n",
    "        else:\n",
    "            version_list.append([v.strip(), ''])\n",
    "    return version_list\n",
    "\n",
    "# Apply the parsing function to 'Versions' column\n",
    "df_versions['versions'] = df_versions['versions'].apply(parse_versions_string)\n",
    "\n",
    "# Function to simplify strings\n",
    "def simplify_string(s):\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r'[^a-z0-9\\s]', '', s)  # Remove special characters\n",
    "    s = re.sub(r'\\s+', ' ', s)  # Replace multiple spaces with single space\n",
    "    s = s.strip()\n",
    "    return s\n",
    "\n",
    "# Simplify relevant columns in df_parsed\n",
    "df_parsed['model name simplified'] = df_parsed['model name simplified'].apply(simplify_string)\n",
    "df_parsed['engine simplified'] = df_parsed['engine'].apply(lambda x: simplify_string(x))\n",
    "df_parsed['drive simplified'] = df_parsed['drive'].apply(lambda x: simplify_string(x))\n",
    "df_parsed['transmission simplified'] = df_parsed['transmission'].apply(lambda x: simplify_string(x))\n",
    "\n",
    "# Function to extract attributes from version name\n",
    "def extract_attributes(version_name):\n",
    "    version_name = version_name.lower()\n",
    "    # Engine extraction\n",
    "    engine_match = re.search(r'(\\d+\\.\\d+|\\d+)(l|t)?', version_name)\n",
    "    engine = engine_match.group(1) if engine_match else ''\n",
    "    # Drive extraction\n",
    "    drive_match = re.search(r'(4x2|4x4|awd|fwd|rwd)', version_name)\n",
    "    drive = drive_match.group(1) if drive_match else ''\n",
    "    # Transmission extraction\n",
    "    transmission_match = re.search(r'\\b(mt|at|manual|aut|automatic)\\b', version_name)\n",
    "    transmission = transmission_match.group(1) if transmission_match else ''\n",
    "    simplified_name = simplify_string(version_name)\n",
    "    return simplified_name, engine, drive, transmission\n",
    "\n",
    "# Initialize a list to hold the matched data\n",
    "matched_data = []\n",
    "\n",
    "for index, row in df_parsed.iterrows():\n",
    "    model_url = row['model url']\n",
    "    model_name_simplified = row['model name simplified']\n",
    "    engine_simplified = row['engine simplified']\n",
    "    drive_simplified = row['drive simplified']\n",
    "    transmission_simplified = row['transmission simplified']\n",
    "\n",
    "    # Get the versions corresponding to this model URL\n",
    "    versions_row = df_versions[df_versions['model url'] == model_url]\n",
    "    if versions_row.empty:\n",
    "        matched_version = None\n",
    "    else:\n",
    "        versions_list = versions_row.iloc[0]['versions']\n",
    "        best_score = -1  # Initialize to -1 to handle zero score cases\n",
    "        best_match = None\n",
    "\n",
    "        # If there is only one version, match it directly\n",
    "        if len(versions_list) == 1:\n",
    "            version = versions_list[0]\n",
    "            version_name, version_url = version\n",
    "            matched_version = {\n",
    "                'Version URL': version_url,\n",
    "            }\n",
    "        else:\n",
    "            for version in versions_list:\n",
    "                version_name, version_url = version\n",
    "                # Extract attributes\n",
    "                version_name_simplified, v_engine, v_drive, v_transmission = extract_attributes(version_name)\n",
    "\n",
    "                # Calculate matching score\n",
    "                name_score = fuzz.token_sort_ratio(model_name_simplified, version_name_simplified)\n",
    "                engine_score = fuzz.partial_ratio(engine_simplified, v_engine) if engine_simplified and v_engine else 0\n",
    "                drive_score = 100 if drive_simplified == v_drive and drive_simplified else 0\n",
    "                transmission_score = 100 if transmission_simplified == v_transmission and transmission_simplified else 0\n",
    "\n",
    "                total_score = name_score + engine_score + drive_score + transmission_score\n",
    "\n",
    "                if total_score > best_score:\n",
    "                    best_score = total_score\n",
    "                    best_match = {\n",
    "                        'Version URL': version_url,\n",
    "                    }\n",
    "\n",
    "            matched_version = best_match\n",
    "\n",
    "    # Ensure that all keys are present even if no match is found\n",
    "    if not matched_version:\n",
    "        matched_version = {\n",
    "            'Version URL': None,\n",
    "        }\n",
    "\n",
    "    # Append matched version to the row\n",
    "    matched_data.append({\n",
    "        **row.to_dict(),\n",
    "        **matched_version\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the matched data\n",
    "df_matched = pd.DataFrame(matched_data)\n",
    "\n",
    "# Remove duplicates based on 'Model Name', 'Engine', 'Drive', 'Transmission'\n",
    "df_matched = df_matched.drop_duplicates(subset=['model name', 'engine', 'drive', 'transmission'])\n",
    "\n",
    "# Save the matched data to a new CSV\n",
    "df_matched.to_csv('csvs/matched_versions.csv', index=False)\n",
    "\n",
    "print(\"Matching completed. Data saved to 'matched_versions.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correr esta celda para obtener el csv final \"scraped_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: changan hunter 1.9l comfort\n",
      "Error fetching https://www.autocosmos.cl/catalogo/2025/changan/hunter/comfort/178826: HTTP 403\n",
      "Failed to fetch https://www.autocosmos.cl/catalogo/2025/changan/hunter/comfort/178826 after 0 retries.\n",
      "Processing model: changan hunter 1.9l comfort 4X4\n",
      "Error fetching https://www.autocosmos.cl/catalogo/2025/changan/hunter/comfort-4x4/178828: HTTP 403\n",
      "Failed to fetch https://www.autocosmos.cl/catalogo/2025/changan/hunter/comfort-4x4/178828 after 0 retries.\n",
      "Processing model: changan hunter 1.9l elite 4X4\n",
      "Error fetching https://www.autocosmos.cl/catalogo/2025/changan/hunter/elite-sport-4x4/178829: HTTP 403\n",
      "Failed to fetch https://www.autocosmos.cl/catalogo/2025/changan/hunter/elite-sport-4x4/178829 after 0 retries.\n",
      "Processing model: changan hunter 1.9l luxury\n",
      "Error fetching https://www.autocosmos.cl/catalogo/2025/changan/hunter/luxury/178827: HTTP 403\n",
      "Failed to fetch https://www.autocosmos.cl/catalogo/2025/changan/hunter/luxury/178827 after 0 retries.\n",
      "Processing model: changan hunter 1.9l luxury 4X4\n",
      "Error fetching https://www.autocosmos.cl/catalogo/2025/changan/hunter/elite-sport-4x4/178829: HTTP 403\n",
      "Failed to fetch https://www.autocosmos.cl/catalogo/2025/changan/hunter/elite-sport-4x4/178829 after 0 retries.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Year'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Year'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m drive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrive\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrive\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     19\u001b[0m transmission \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransmission\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransmission\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 20\u001b[0m year \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     21\u001b[0m version_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVersion URL\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVersion URL\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Create the MODEL column and remove any 'nan' substrings\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Year'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Read the matched_versions.csv file\n",
    "df_matched = pd.read_csv('csvs/matched_versions.csv')\n",
    "\n",
    "# Initialize a list to hold the output data\n",
    "output_data = []\n",
    "\n",
    "for index, row in df_matched.iterrows():\n",
    "    # Extract necessary fields and handle 'nan' values\n",
    "    marca = str(row['marca']) if not pd.isna(row['marca']) else ''\n",
    "    model_name = str(row['model name']) if not pd.isna(row['model name']) else ''\n",
    "    engine = str(row['engine']) if not pd.isna(row['engine']) else ''\n",
    "    drive = str(row['drive']) if not pd.isna(row['drive']) else ''\n",
    "    transmission = str(row['transmission']) if not pd.isna(row['transmission']) else ''\n",
    "    year = str(row['year']) if not pd.isna(row['year']) else ''\n",
    "    version_url = str(row['Version URL']) if not pd.isna(row['Version URL']) else ''\n",
    "\n",
    "    # Create the MODEL column and remove any 'nan' substrings\n",
    "    model = ' '.join([marca, model_name, engine, drive, transmission, year])\n",
    "    model = model.replace('nan', '').strip()\n",
    "\n",
    "    # Remove any extra spaces\n",
    "    model = ' '.join(model.split())\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Processing model: {model}\")\n",
    "\n",
    "    # Check if version_url is valid\n",
    "    if not version_url or pd.isna(version_url) or version_url.lower() == 'nan':\n",
    "        print(f\"Skipping {model} due to invalid Version URL\")\n",
    "        continue  # Skip to next row\n",
    "\n",
    "    # Initialize retry parameters\n",
    "    retries = 0\n",
    "    max_retries = 20\n",
    "    success = False\n",
    "\n",
    "    while retries < max_retries and not success:\n",
    "        try:\n",
    "            response = requests.get(version_url)\n",
    "            if response.status_code == 200:\n",
    "                success = True\n",
    "                html_content = response.content\n",
    "            elif response.status_code == 500:\n",
    "                retries += 1\n",
    "                time.sleep(1)  # Wait for 1 second before retrying\n",
    "                continue\n",
    "            else:\n",
    "                # Handle other HTTP errors\n",
    "                print(f\"Error fetching {version_url}: HTTP {response.status_code}\")\n",
    "                break\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request exception for {version_url}: {e}\")\n",
    "            break\n",
    "\n",
    "    if not success:\n",
    "        print(f\"Failed to fetch {version_url} after {retries} retries.\")\n",
    "        continue  # Skip to next row\n",
    "\n",
    "    # Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Initialize a dictionary to hold the attributes\n",
    "    attributes = {}\n",
    "\n",
    "    # Scrape 'Especificaciones técnicas' section\n",
    "    especificaciones_section = soup.find('section', {'id': 'especificaciones'})\n",
    "    if especificaciones_section:\n",
    "        # Extract all tables within this section\n",
    "        tables = especificaciones_section.find_all('table', {'class': 'ficha'})\n",
    "        for table in tables:\n",
    "            # Get the caption (category)\n",
    "            caption_tag = table.find('caption')\n",
    "            category = caption_tag.get_text(strip=True) if caption_tag else 'Unknown'\n",
    "\n",
    "            # For each row in the table\n",
    "            rows = table.find_all('tr')\n",
    "            for row_tr in rows:\n",
    "                cols = row_tr.find_all('td')\n",
    "                if len(cols) == 2:\n",
    "                    attr_name = cols[0].get_text(strip=True)\n",
    "                    attr_value = cols[1].get_text(strip=True)\n",
    "                    # Prefix the attribute name with the category to avoid duplicates\n",
    "                    key = f\"{category} - {attr_name}\"\n",
    "                    attributes[key] = attr_value\n",
    "    else:\n",
    "        print(f\"No 'Especificaciones técnicas' section found in {version_url}\")\n",
    "        # We can continue to scrape 'Equipamiento' even if 'Especificaciones técnicas' is missing\n",
    "\n",
    "    # Scrape 'Equipamiento' section\n",
    "    equipamiento_section = soup.find('section', {'id': 'equipamiento'})\n",
    "    if equipamiento_section:\n",
    "        # Extract all tables within this section\n",
    "        tables = equipamiento_section.find_all('table', {'class': 'ficha'})\n",
    "        for table in tables:\n",
    "            # Get the caption (category)\n",
    "            caption_tag = table.find('caption')\n",
    "            category = caption_tag.get_text(strip=True) if caption_tag else 'Unknown'\n",
    "\n",
    "            # For each row in the table\n",
    "            rows = table.find_all('tr')\n",
    "            for row_tr in rows:\n",
    "                cols = row_tr.find_all('td')\n",
    "                if len(cols) == 2:\n",
    "                    attr_name = cols[0].get_text(strip=True)\n",
    "                    attr_value = cols[1].get_text(strip=True)\n",
    "                    # Prefix the attribute name with the category to avoid duplicates\n",
    "                    key = f\"{category} - {attr_name}\"\n",
    "                    attributes[key] = attr_value\n",
    "    else:\n",
    "        print(f\"No 'Equipamiento' section found in {version_url}\")\n",
    "\n",
    "    # Create a dictionary for this row\n",
    "    data_row = {\n",
    "        'model': model,\n",
    "        'marca': marca,\n",
    "        'model name': model_name,\n",
    "        'engine': engine,\n",
    "        'drive': drive,\n",
    "        'transmission': transmission,\n",
    "        'year': year,\n",
    "        'version url': version_url\n",
    "    }\n",
    "    data_row.update(attributes)\n",
    "\n",
    "    # Replace 'nan' with empty string in data_row values\n",
    "    data_row = {k: ('' if v == 'nan' else v) for k, v in data_row.items()}\n",
    "\n",
    "    # Append to output_data\n",
    "    output_data.append(data_row)\n",
    "\n",
    "# Create a DataFrame from the output data\n",
    "df_output = pd.DataFrame(output_data)\n",
    "\n",
    "# Drop columns that are entirely empty\n",
    "df_output.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Replace NaN values with empty strings\n",
    "df_output.fillna('', inplace=True)\n",
    "\n",
    "# Save to a new CSV file\n",
    "df_output.to_csv('csvs/scraped_data.csv', index=False)\n",
    "\n",
    "print(\"Data scraping completed. Results saved to 'scraped_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
