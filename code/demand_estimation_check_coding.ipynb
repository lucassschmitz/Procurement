{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file useses the purchases of only the 2021 FA, because we need prod. char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandasgui\n",
    "!pip install pyblp \n",
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandasgui in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.2.14)\n",
      "Requirement already satisfied: pandas in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandasgui) (2.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandasgui) (1.24.3)\n",
      "Requirement already satisfied: PyQt5 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandasgui) (5.15.11)\n",
      "Requirement already satisfied: PyQt5-sip in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandasgui) (12.15.0)\n",
      "Requirement already satisfied: PyQtWebEngine in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandasgui) (5.15.7)\n",
      "Requirement already satisfied: plotly in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandasgui) (5.23.0)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandasgui) (1.9.3)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from pandasgui) (65.5.0)\n",
      "Requirement already satisfied: appdirs in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandasgui) (1.4.4)\n",
      "Requirement already satisfied: pynput in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandasgui) (1.7.7)\n",
      "Requirement already satisfied: IPython in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandasgui) (8.13.2)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandasgui) (17.0.0)\n",
      "Requirement already satisfied: astor in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandasgui) (0.8.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandasgui) (4.10.0)\n",
      "Requirement already satisfied: qtstylish>=0.1.2 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandasgui) (0.1.5)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandasgui) (306)\n",
      "Requirement already satisfied: backcall in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython->pandasgui) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython->pandasgui) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython->pandasgui) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython->pandasgui) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython->pandasgui) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython->pandasgui) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython->pandasgui) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython->pandasgui) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython->pandasgui) (5.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython->pandasgui) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->pandasgui) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->pandasgui) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->pandasgui) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from plotly->pandasgui) (8.5.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from plotly->pandasgui) (23.1)\n",
      "Requirement already satisfied: six in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pynput->pandasgui) (1.16.0)\n",
      "Requirement already satisfied: PyQt5-Qt5<5.16.0,>=5.15.2 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from PyQt5->pandasgui) (5.15.2)\n",
      "Requirement already satisfied: PyQtWebEngine-Qt5<5.16.0,>=5.15.0 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from PyQtWebEngine->pandasgui) (5.15.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wordcloud->pandasgui) (9.5.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wordcloud->pandasgui) (3.7.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jedi>=0.16->IPython->pandasgui) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->IPython->pandasgui) (0.2.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud->pandasgui) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud->pandasgui) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud->pandasgui) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud->pandasgui) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud->pandasgui) (3.0.9)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from stack-data->IPython->pandasgui) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from stack-data->IPython->pandasgui) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from stack-data->IPython->pandasgui) (0.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\lucas\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyblp in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyblp) (1.24.3)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyblp) (0.5.6)\n",
      "Requirement already satisfied: pyhdfe>=0.1.0 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyblp) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyblp) (1.10.1)\n",
      "Requirement already satisfied: sympy>=1.1.0 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyblp) (1.13.1)\n",
      "Requirement already satisfied: six in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from patsy>=0.5.1->pyblp) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.1.0->pyblp) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\lucas\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.3.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\lucas\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns\n",
    "from pandasgui import show\n",
    "import socket\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "import unicodedata\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "import pyblp\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_market_shares_with_outside_good(df_transac, share_adjustment = True):\n",
    "    \"\"\"\n",
    "    Calculate market shares using market-specific N_i from the DataFrame\n",
    "    \"\"\"\n",
    "    # Group by product (j) and market (t) to count purchases\n",
    "    product_counts = df_transac.groupby(['product_ids', 'market_ids']).size().reset_index(name='purchases')\n",
    "    \n",
    "    # Get N_i for each market (taking first occurrence since it's constant within market)\n",
    "    market_populations = df_transac.groupby('market_ids')['N_i'].first().reset_index()\n",
    "    \n",
    "    # Merge N_i with product counts\n",
    "    product_counts = product_counts.merge(market_populations, on='market_ids')\n",
    "    \n",
    "    # Calculate market shares\n",
    "    if share_adjustment: \n",
    "        product_counts['shares'] = np.minimum(10*product_counts['purchases'] / product_counts['N_i'], 0.5)\n",
    "    else: \n",
    "        product_counts['shares'] = product_counts['purchases'] / product_counts['N_i']\n",
    "    \n",
    "    product_counts['shares_real'] =product_counts['purchases'] / product_counts['N_i']\n",
    "                                               \n",
    "    x_vars = [col for col in df_transac.columns if col.startswith('x')] #list of variables starting with x \n",
    "    \n",
    "    # Get product characteristics\n",
    "    product_chars = df_transac.groupby(['product_ids', 'market_ids']).agg(\n",
    "        {var: 'first' for var in x_vars} | {'prices': 'first', 'model_id': 'first'}\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Merge market shares with product characteristics\n",
    "    final_df = product_chars.merge(product_counts[['product_ids', 'market_ids', 'shares', 'shares_real']], on=['product_ids', 'market_ids'])\n",
    "    \n",
    "    # Calculate outside good share for each market\n",
    "    market_shares = final_df.groupby('market_ids')['shares'].sum()\n",
    "    outside_shares = 1 - market_shares\n",
    "    market_shares_real = final_df.groupby('market_ids')['shares_real'].sum()\n",
    "    outside_shares_real = 1 - market_shares_real\n",
    "    \n",
    "    \n",
    "    # Create outside good rows\n",
    "    markets = df_transac['market_ids'].unique()\n",
    "    outside_goods = pd.DataFrame()\n",
    "    outside_goods['market_ids'] = markets\n",
    "    outside_goods['product_ids'] = 0\n",
    "\n",
    "    for var in x_vars:\n",
    "        if pd.api.types.is_numeric_dtype(df_transac[var]):\n",
    "            outside_goods[var] = 0  # Set numeric variables to 0\n",
    "        else:\n",
    "            outside_goods[var] = '-'  # Set categorical variables to '-'\n",
    "    \n",
    "    outside_goods['prices'] = 0\n",
    "    outside_goods['shares'] = [outside_shares[t] for t in markets]\n",
    "    outside_goods['shares_real'] = [outside_shares_real[t] for t in markets]\n",
    "\n",
    "    # Combine outside goods with other products\n",
    "    final_df = pd.concat([final_df, outside_goods])\n",
    "    \n",
    "    # Sort by market and product ID\n",
    "    final_df = final_df.sort_values(['market_ids', 'product_ids'])\n",
    "    \n",
    "    final_df['model_id'] = final_df['model_id'] + 1 \n",
    "    final_df['model_id'] = final_df['model_id'].fillna(0)\n",
    "    return final_df\n",
    "\n",
    "def normalize_shares(group):\n",
    "    \"\"\"\n",
    "    Function to normalize shares for each market\n",
    "    \"\"\"\n",
    "    # Fix shares that are not negative\n",
    "    total_shares = group[group['shares'] > 0.01]['shares'].sum()\n",
    "    scaling_factor = 0.99 - group[group['shares'] == 0.01]['shares'].sum()\n",
    "    if total_shares > 0:  # Avoid division by zero\n",
    "        group.loc[group['shares'] > 0.01, 'shares'] *= scaling_factor / total_shares\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\OneDrive - Yale University\\Documents\\GitHub\\2nd-year-paper\\interm_data\\yearly_data\\Transacciones\\transac_with_chars.csv\n"
     ]
    }
   ],
   "source": [
    "car_path = os.path.join('..', 'interm_data', 'yearly_data', 'Transacciones', 'transac_with_chars.csv')\n",
    "print(os.path.abspath(car_path))\n",
    "df = pd.read_csv(car_path, encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. select vars that could be relevant\n",
    "2. rename prod. char as x1, x2.. and do other renaming \n",
    "3.  to reduce fixed effects if a variable is categorical and has more than 5 values we remove it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique values in x1: 4\n",
      "number of unique values in x2: 65\n",
      "number of unique values in x3: 3\n",
      "number of unique values in x4: 17\n",
      "number of unique values in x5: 39\n",
      "number of unique values in x6: 132\n",
      "number of unique values in x7: 119\n",
      "number of unique values in x8: 93\n",
      "number of unique values in x9: 5\n",
      "number of unique values in x10: 8\n",
      "number of unique values in x11: 4\n",
      "number of unique values in x12: 8\n",
      "number of unique values in x13: 21\n",
      "number of unique values in x14: 2\n",
      "number of unique values in x15: 39\n",
      "number of unique values in x16: 6\n",
      "number of unique values in x17: 1\n",
      "number of unique values in x18: 7\n",
      "number of unique values in x19: 12\n",
      "number of unique values in x20: 8\n"
     ]
    }
   ],
   "source": [
    "#### 1. variable selection \n",
    "char_list  = [\"Motor - Combustible\", \"Motor - Cilindrada\",\n",
    "    \"TransmisiÃ³n y chasis - Motor - tracciÃ³n\", \"TransmisiÃ³n y chasis - TransmisiÃ³n\",\n",
    "    \"TransmisiÃ³n y chasis - SuspensiÃ³n trasera\", \"Medidas y capacidades - Largo\",\n",
    "    \"Medidas y capacidades - Alto\", \"Medidas y capacidades - Distancia entre ejes\",\n",
    "    \"Confort - Aire acondicionado\", \"Confort - Tapizados\", \"Confort - Cierre de puertas\", \n",
    "    \"Confort - Vidrios (del. - tras.)\", \"Confort - Espejos exteriores\", \"Confort - Espejo interior\",\n",
    "    \"Confort - Faros delanteros\", \"Confort - Faros antiniebla\", \"Confort - Computadora de a bordo\",\n",
    "    \"Confort - DirecciÃ³n asistida\", \"Seguridad - Airbags\", \"Tipo de Producto\"]\n",
    "\n",
    "model_vars = [\"IDProductoCM\",  \"Modelo\",  \"Marca\", 'simplified_model',\n",
    "            \"Precio Unitario\", \"Rut Unidad de Compra\", \"RegiÃ³n Unidad de Compra\", \"Sector\",\n",
    "            \"year_df\", \"Nro LicitaciÃ³n PÃºblica\", \"Fecha EnvÃ­o OC\", \"Cantidad\", \"Rut Proveedor\",\n",
    "             \"Nombre Proveedor Sucursal\", ]\n",
    "df = df[model_vars + char_list]\n",
    "\n",
    "\n",
    "### 2. rename vars \n",
    "for n, col in enumerate(char_list, start=1):  # Start numbering from 1\n",
    "    df.rename(columns={col: f'x{n}'}, inplace=True)\n",
    "\n",
    "df = df.rename(columns={\n",
    "    'Fecha EnvÃ­o OC': 'Fecha',\n",
    "    'RegiÃ³n Unidad de Compra': 'Region', \n",
    "    'IDProductoCM': 'product_ids',\n",
    "})\n",
    "\n",
    "### 3. drop vars to reduce number of parameters to estimate\n",
    "for n, col in enumerate(char_list, start=1):  # Start numbering from 1\n",
    "    print(f\"number of unique values in {f'x{n}'}: {df[f'x{n}'].nunique()}\")\n",
    "\n",
    "\n",
    "drop_list = ['x4', 'x5', 'x10', 'x12', 'x13','x15',  'x16', 'x17', 'x18', 'x19']\n",
    "df = df.drop(drop_list, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create month-year \n",
    "2. create markets and number of consumers\n",
    "3. create consumer group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217\n"
     ]
    }
   ],
   "source": [
    "#1. create month-year \n",
    "df['Fecha'] = pd.to_datetime(df['Fecha'], errors='coerce')\n",
    "df['month'] = df['Fecha'].dt.month\n",
    "df['year'] = df['Fecha'].dt.year\n",
    "df.drop('Fecha', axis=1, inplace=True)\n",
    "\n",
    "#2. define the market and the number of consumers in the market \n",
    "df['semester'] = ((df['month'] - 1) // 6) + 1\n",
    "df['market_ids'] = df.groupby(['year', 'semester', 'Region']).ngroup()\n",
    "print(df['market_ids'].nunique())\n",
    "\n",
    "region_counts = df.groupby('Region')['market_ids'].nunique()\n",
    "df['N_i'] = df['Region'].map(region_counts)\n",
    "\n",
    "## 3. create consumer groups based on zone-sector\n",
    "#print(df['Region'].unique())\n",
    "Norte = ['Arica y Parinacota', 'TarapacÃ\\x83Â\\x83Ã\\x82Â¡', 'Antofagasta', 'Atacama', 'Coquimbo']\n",
    "Centro = [\"Lib. Gral. Bdo. O'Higgins\", 'Maule', 'Metropolitana', 'ValparaÃ\\x83Â\\x83Ã\\x82Â\\xadso' ]\n",
    "Sur = ['BÃ\\x83Â\\x83Ã\\x82Â\\xado-BÃ\\x83Â\\x83Ã\\x82Â\\xado', 'Los RÃ\\x83Â\\x83Ã\\x82Â\\xados', 'Ã\\x83Â\\x83Ã\\x82Â\\x91uble',\n",
    "    'Los Lagos', 'AraucanÃ\\x83Â\\x83Ã\\x82Â\\xada', 'Magallanes y AntÃ\\x83Â\\x83Ã\\x82Â¡rtica', 'AysÃ\\x83Â\\x83Ã\\x82Â©n']\n",
    "\n",
    "\n",
    "def get_zone(region):\n",
    "    if region in Norte:\n",
    "        return 'Norte'\n",
    "    elif region in Centro:\n",
    "        return 'Centro'\n",
    "    elif region in Sur:\n",
    "        return 'Sur'\n",
    "    else:\n",
    "        return 'Other'  # For any regions not in the lists\n",
    "df['Zona'] = df['Region'].apply(get_zone)\n",
    "#df['k'] = df.groupby(['Sector', 'Zona']).ngroup()\n",
    "df['k'] = df.groupby('Sector').ngroup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. generate unique identifier by simplified model \n",
    "1. convert to numeric values and drop chars with NaNs \n",
    "2. drop columns with NaNs since they can not be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0. \n",
    "# Create a dictionary mapping unique models to IDs\n",
    "model_to_id = {model: idx for idx, model in enumerate(df['simplified_model'].unique())}\n",
    "\n",
    "# Create new column with the numeric IDs\n",
    "df['model_id'] = df['simplified_model'].map(model_to_id)\n",
    "\n",
    "\n",
    "# 1. convert to numeric values and drop chars with NaNs \n",
    "def extract_number(value):\n",
    "    if pd.isna(value) or value == 'N/D':\n",
    "        return np.nan\n",
    "    # Extract numbers using string methods\n",
    "    if isinstance(value, str):\n",
    "        # Find first sequence of numbers (including decimals)\n",
    "        numbers = ''.join(c for c in value if c.isdigit() or c == '.')\n",
    "        return float(numbers) if numbers else value\n",
    "    return value\n",
    "\n",
    "for column in df.columns:\n",
    "    try:\n",
    "        df[column] = df[column].apply(extract_number)\n",
    "    except:\n",
    "        continue # If conversion fails, keep the original values\n",
    "\n",
    "\n",
    "## 2. drop rows with NaNs\n",
    "x_columns = [col for col in df.columns if col.startswith('x')]\n",
    "x_columns_with_missing = [col for col in x_columns if df[col].isna().any()] #cols start with x and have NaNs\n",
    "non_x_columns = [col for col in df.columns if not col.startswith('x')] # Get non-x columns \n",
    "df = df.drop(columns=x_columns_with_missing) # Drop x-columns with missing values\n",
    "\n",
    "remaining_x_columns = [col for col in df.columns if col.startswith('x')]\n",
    "new_x_names = [f'x{i+1}' for i in range(len(remaining_x_columns))] #rename x cols so that they dont skip numbers \n",
    "rename_dict = dict(zip(remaining_x_columns, new_x_names))\n",
    "df = df.rename(columns=rename_dict) # Rename only the x-columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prices'] = df['Precio Unitario'].replace(r',.*', '', regex=True) #remove commas from numbers\n",
    "\n",
    "columns_to_convert = ['prices'] \n",
    "\n",
    "# Convert the specified columns to numeric\n",
    "df[columns_to_convert] = df[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only keep product categories with more than 100 obs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x6\n",
      "CAMIONETA          2183\n",
      "SUV                 894\n",
      "MINIBUS             364\n",
      "SEDÃN              232\n",
      "CAMIÃN LIVIANO      97\n",
      "FURGÃN              88\n",
      "HATCHBACK            35\n",
      "CARGO                 1\n",
      "Name: count, dtype: int64\n",
      "Categories and their counts:\n",
      "CAMIONETA: 2183\n",
      "SUV: 894\n",
      "MINIBUS: 364\n",
      "SEDÃN: 232\n",
      "CAMIÃN LIVIANO: 97\n",
      "FURGÃN: 88\n",
      "HATCHBACK: 35\n",
      "CARGO: 1\n"
     ]
    }
   ],
   "source": [
    "print(df.value_counts('x6'))\n",
    "# Look at value counts and drop categories with less than 100 occurrences\n",
    "x6_counts = df['x6'].value_counts()\n",
    "print(\"Categories and their counts:\")\n",
    "for cat, count in x6_counts.items():\n",
    "    print(f\"{cat}: {count}\")\n",
    "\n",
    "# Keep only categories with >= 100 occurrences \n",
    "valid_categories = x6_counts[x6_counts >= 100].index\n",
    "df['x6'] = df['x6'].apply(lambda x: x if x in valid_categories else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data = calculate_market_shares_with_outside_good(df, share_adjustment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check that shares 1. are positive and 2. sum upp to less than 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of negative shares: 3.17%\n",
      "count    217.000000\n",
      "mean       0.313687\n",
      "std        0.331115\n",
      "min        0.001582\n",
      "25%        0.011676\n",
      "50%        0.136054\n",
      "75%        0.634921\n",
      "max        0.884354\n",
      "Name: shares, dtype: float64\n",
      "Percentage of negative shares: 0.00%\n",
      "Series([], Name: shares, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "###1. Check for negative shares\n",
    "# percentage of neg shares. (if share is negative replace by 2%)\n",
    "negative_shares_percentage = (product_data['shares'] < 0).mean() * 100\n",
    "print(f\"Percentage of negative shares: {negative_shares_percentage:.2f}%\")\n",
    "product_data['shares'] = product_data['shares'].apply(lambda x: 0.02 if x < 0.02 else x)\n",
    "\n",
    "#shares have to sum up to 1%, normalize  by market_ids\n",
    "product_data['shares_sum'] = product_data.groupby('market_ids')['shares'].transform('sum')\n",
    "product_data['shares'] = product_data['shares'] / (product_data['shares_sum']+0.05) # add 0.05 since shares have to sum up to less than 1. \n",
    "\n",
    "# 3. check that outside shares are not too high and that there are no negative shares\n",
    "outside_good_shares = product_data[product_data['product_ids'] == 0]['shares'].describe()\n",
    "print(outside_good_shares)\n",
    "negative_shares_percentage = (product_data['shares'] < 0).mean() * 100\n",
    "print(f\"Percentage of negative shares: {negative_shares_percentage:.2f}%\")\n",
    "\n",
    "# 4. check that no share sum up to more than 1 \n",
    "sum_market_shares = product_data.groupby('market_ids')['shares'].sum()\n",
    "markets_with_high_shares = sum_market_shares[(sum_market_shares > 1) ]\n",
    "print(markets_with_high_shares)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store = df.copy()\n",
    "product_data_store = product_data.copy() # to have a copy of the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Py-BLP with micro-moments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "product_data is the data with the prices/shares/prod char,  in the documentation called product data\n",
    "agent_data is the data with the demographics, in our case it has the distribution of demographics. \n",
    "\n",
    "\\begin{align*}\n",
    "    &E[\\text{i purchases new vehicle} \\mid \\{\\bar{y}_i < \\bar{y}_1\\}], \\\\\n",
    "    &E[\\text{i purchases new vehicle} \\mid \\{\\bar{y}_1 \\leq \\bar{y}_i < \\bar{y}_2\\}], \\\\\n",
    "    &E[\\text{i purchases new vehicle} \\mid \\{\\bar{y}_i \\geq \\bar{y}_2\\}];\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    &E[f_{si} \\mid \\{\\text{i purchases a minivan}\\}], \\\\\n",
    "    &E[f_{si} \\mid \\{\\text{i purchases a station wagon}\\}], \\\\\n",
    "    &E[f_{si} \\mid \\{\\text{i purchases a sport-utility}\\}], \\\\\n",
    "    &E[f_{si} \\mid \\{\\text{i purchases a full-size van}\\}].\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each market create one obs. for each local agency in the market. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. product_data needs to have instruments explicitly defined as demand_instruments{i} variables? I am not sure because chat gpt at some pooint said that X1 variables automatically become instruments. \n",
    "\n",
    "2. the best way of dealing with categorical variables is to create lists of dummies, for example if you have k (consumer type) that takes values from 0 to 10 it is better to create k1 to k11. This makes it easier to create the micro-parts using the agent formulation. \n",
    "The same applies with product characteristics that are dummies and will be used to create micro-parts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_store.copy() #restore the original data\n",
    "product_data = product_data_store.copy() #restore the original data \n",
    "product_data.drop(columns = ['product_ids'], inplace =  True )\n",
    "product_data.rename(columns = {'model_id': 'product_ids'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['k_0', 'k_1', 'k_2', 'k_3', 'k_4', 'k_5', 'k_6']\n"
     ]
    }
   ],
   "source": [
    "# create dummies for k \n",
    "k_dummies = pd.get_dummies(df['k'], prefix='k', dtype=int)\n",
    "df = pd.concat([df, k_dummies], axis=1)\n",
    "k_list = k_dummies.columns.tolist()\n",
    "#k_list.remove('k_6')\n",
    "#k_list.remove('k_5')\n",
    "print(k_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform x6 to dummy vars x7 to xN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x8', 'x9', 'x11', 'x12']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique categories from one dataset (assuming the categories are the same in both datasets)\n",
    "categories = product_data['x6'].unique()\n",
    "\n",
    "# Step 1: Create dummies for product_data\n",
    "dummies_product = pd.get_dummies(product_data['x6'], dtype=int)\n",
    "dummies_product = dummies_product.reindex(columns=categories, fill_value=0)\n",
    "dummies_product.columns = [f\"x{i}\" for i in range(7, 7 + len(categories))]\n",
    "product_data = pd.concat([product_data, dummies_product], axis=1)\n",
    "\n",
    "# Step 2: Create dummies for df\n",
    "dummies_df = pd.get_dummies(df['x6'], dtype=int)\n",
    "dummies_df = dummies_df.reindex(columns=categories, fill_value=0)\n",
    "dummies_df.columns = [f\"x{i}\" for i in range(7, 7 + len(categories))]\n",
    "df = pd.concat([df, dummies_df], axis=1)\n",
    "car_type_dummies = ['x8', 'x9',  'x11', 'x12'] #do not include 'x10' because it was causing collinearity issues. \n",
    "\n",
    "print(car_type_dummies)\n",
    "product_data.drop('x7', axis= 1,  inplace = True) #is a dummy for missing values \n",
    "\n",
    "#car_type_dummies = ['x8', 'x9', 'x10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate agent data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_ids</th>\n",
       "      <th>weights</th>\n",
       "      <th>k</th>\n",
       "      <th>nodes0</th>\n",
       "      <th>nodes1</th>\n",
       "      <th>nodes2</th>\n",
       "      <th>nodes3</th>\n",
       "      <th>nodes4</th>\n",
       "      <th>nodes5</th>\n",
       "      <th>nodes6</th>\n",
       "      <th>...</th>\n",
       "      <th>nodes8</th>\n",
       "      <th>nodes9</th>\n",
       "      <th>nodes10</th>\n",
       "      <th>k_0</th>\n",
       "      <th>k_1</th>\n",
       "      <th>k_2</th>\n",
       "      <th>k_3</th>\n",
       "      <th>k_4</th>\n",
       "      <th>k_5</th>\n",
       "      <th>k_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1.472936</td>\n",
       "      <td>1.749826</td>\n",
       "      <td>0.277410</td>\n",
       "      <td>4.465586</td>\n",
       "      <td>1.221116</td>\n",
       "      <td>3.420080</td>\n",
       "      <td>0.745126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030344</td>\n",
       "      <td>1.625646</td>\n",
       "      <td>1.490579</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1.874038</td>\n",
       "      <td>1.091387</td>\n",
       "      <td>0.253513</td>\n",
       "      <td>0.259205</td>\n",
       "      <td>0.938425</td>\n",
       "      <td>3.946507</td>\n",
       "      <td>12.610528</td>\n",
       "      <td>...</td>\n",
       "      <td>4.912883</td>\n",
       "      <td>3.649473</td>\n",
       "      <td>5.434057</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1.790057</td>\n",
       "      <td>8.055982</td>\n",
       "      <td>3.225583</td>\n",
       "      <td>5.863133</td>\n",
       "      <td>2.433661</td>\n",
       "      <td>3.220127</td>\n",
       "      <td>3.922476</td>\n",
       "      <td>...</td>\n",
       "      <td>1.701982</td>\n",
       "      <td>1.774889</td>\n",
       "      <td>4.423523</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.764926</td>\n",
       "      <td>8.433982</td>\n",
       "      <td>2.123790</td>\n",
       "      <td>1.666927</td>\n",
       "      <td>1.836264</td>\n",
       "      <td>0.398224</td>\n",
       "      <td>3.423341</td>\n",
       "      <td>...</td>\n",
       "      <td>1.572102</td>\n",
       "      <td>2.059631</td>\n",
       "      <td>9.043988</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1.636307</td>\n",
       "      <td>2.174726</td>\n",
       "      <td>0.167153</td>\n",
       "      <td>2.912481</td>\n",
       "      <td>2.724134</td>\n",
       "      <td>1.631412</td>\n",
       "      <td>2.021295</td>\n",
       "      <td>...</td>\n",
       "      <td>1.216795</td>\n",
       "      <td>1.971932</td>\n",
       "      <td>2.458951</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21695</th>\n",
       "      <td>216</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>3.307148</td>\n",
       "      <td>1.473756</td>\n",
       "      <td>4.700954</td>\n",
       "      <td>1.597808</td>\n",
       "      <td>2.243162</td>\n",
       "      <td>8.936660</td>\n",
       "      <td>1.304072</td>\n",
       "      <td>...</td>\n",
       "      <td>2.393040</td>\n",
       "      <td>4.969297</td>\n",
       "      <td>2.975508</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21696</th>\n",
       "      <td>216</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>5.427338</td>\n",
       "      <td>1.826279</td>\n",
       "      <td>11.441033</td>\n",
       "      <td>1.572075</td>\n",
       "      <td>5.546083</td>\n",
       "      <td>2.503798</td>\n",
       "      <td>7.851869</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489206</td>\n",
       "      <td>1.814205</td>\n",
       "      <td>9.722421</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21697</th>\n",
       "      <td>216</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>3.157814</td>\n",
       "      <td>3.906189</td>\n",
       "      <td>5.198243</td>\n",
       "      <td>1.806855</td>\n",
       "      <td>1.136933</td>\n",
       "      <td>12.843746</td>\n",
       "      <td>8.739671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188150</td>\n",
       "      <td>3.663534</td>\n",
       "      <td>2.180201</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21698</th>\n",
       "      <td>216</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>3.328665</td>\n",
       "      <td>1.811795</td>\n",
       "      <td>3.434160</td>\n",
       "      <td>3.859996</td>\n",
       "      <td>2.931855</td>\n",
       "      <td>2.477535</td>\n",
       "      <td>4.419991</td>\n",
       "      <td>...</td>\n",
       "      <td>1.292895</td>\n",
       "      <td>0.700553</td>\n",
       "      <td>2.563057</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21699</th>\n",
       "      <td>216</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>3.645847</td>\n",
       "      <td>3.751791</td>\n",
       "      <td>0.784987</td>\n",
       "      <td>7.566599</td>\n",
       "      <td>1.479514</td>\n",
       "      <td>0.571210</td>\n",
       "      <td>1.419071</td>\n",
       "      <td>...</td>\n",
       "      <td>1.336132</td>\n",
       "      <td>4.530485</td>\n",
       "      <td>4.643960</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21700 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       market_ids  weights  k    nodes0    nodes1     nodes2    nodes3   \n",
       "0               0     0.01  3  1.472936  1.749826   0.277410  4.465586  \\\n",
       "1               0     0.01  3  1.874038  1.091387   0.253513  0.259205   \n",
       "2               0     0.01  3  1.790057  8.055982   3.225583  5.863133   \n",
       "3               0     0.01  3  0.764926  8.433982   2.123790  1.666927   \n",
       "4               0     0.01  3  1.636307  2.174726   0.167153  2.912481   \n",
       "...           ...      ... ..       ...       ...        ...       ...   \n",
       "21695         216     0.01  3  3.307148  1.473756   4.700954  1.597808   \n",
       "21696         216     0.01  3  5.427338  1.826279  11.441033  1.572075   \n",
       "21697         216     0.01  3  3.157814  3.906189   5.198243  1.806855   \n",
       "21698         216     0.01  1  3.328665  1.811795   3.434160  3.859996   \n",
       "21699         216     0.01  3  3.645847  3.751791   0.784987  7.566599   \n",
       "\n",
       "         nodes4     nodes5     nodes6  ...    nodes8    nodes9   nodes10   \n",
       "0      1.221116   3.420080   0.745126  ...  0.030344  1.625646  1.490579  \\\n",
       "1      0.938425   3.946507  12.610528  ...  4.912883  3.649473  5.434057   \n",
       "2      2.433661   3.220127   3.922476  ...  1.701982  1.774889  4.423523   \n",
       "3      1.836264   0.398224   3.423341  ...  1.572102  2.059631  9.043988   \n",
       "4      2.724134   1.631412   2.021295  ...  1.216795  1.971932  2.458951   \n",
       "...         ...        ...        ...  ...       ...       ...       ...   \n",
       "21695  2.243162   8.936660   1.304072  ...  2.393040  4.969297  2.975508   \n",
       "21696  5.546083   2.503798   7.851869  ...  1.489206  1.814205  9.722421   \n",
       "21697  1.136933  12.843746   8.739671  ...  0.188150  3.663534  2.180201   \n",
       "21698  2.931855   2.477535   4.419991  ...  1.292895  0.700553  2.563057   \n",
       "21699  1.479514   0.571210   1.419071  ...  1.336132  4.530485  4.643960   \n",
       "\n",
       "         k_0    k_1    k_2    k_3    k_4    k_5    k_6  \n",
       "0      False  False  False   True  False  False  False  \n",
       "1      False  False  False   True  False  False  False  \n",
       "2      False  False  False   True  False  False  False  \n",
       "3      False  False  False   True  False  False  False  \n",
       "4      False  False  False   True  False  False  False  \n",
       "...      ...    ...    ...    ...    ...    ...    ...  \n",
       "21695  False  False  False   True  False  False  False  \n",
       "21696  False  False  False   True  False  False  False  \n",
       "21697  False  False  False   True  False  False  False  \n",
       "21698  False   True  False  False  False  False  False  \n",
       "21699  False  False  False   True  False  False  False  \n",
       "\n",
       "[21700 rows x 21 columns]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_agent_data(product_data, df, N=100):\n",
    "    # Validate inputs\n",
    "    if 'market_ids' not in product_data.columns or 'market_ids' not in df.columns:\n",
    "        raise ValueError(\"Both product_data and df must have a 'market_ids' column.\")\n",
    "    if 'k' not in df.columns:\n",
    "        raise ValueError(\"The 'df' dataframe must contain a 'k' column.\")\n",
    "    \n",
    "    # Get unique market IDs\n",
    "    market_ids = product_data['market_ids'].unique()\n",
    "    \n",
    "    # Create empty lists to store data\n",
    "    agent_data_list = []\n",
    "    \n",
    "    # Generate data for each market\n",
    "    for market_id in market_ids:\n",
    "        # Generate market IDs and weights\n",
    "        market_ids_i = np.full(N, market_id)\n",
    "        weights_i = np.full(N, 1 / N)\n",
    "        \n",
    "        # Generate nodes from chi-square(3) distribution\n",
    "        nodes_i = chi2.rvs(df=3, size=(N, 11))\n",
    "        \n",
    "        # Get k distribution for this market\n",
    "        market_k = df[df['market_ids'] == market_id]['k'].value_counts()\n",
    "        if market_k.empty:\n",
    "            raise ValueError(f\"No 'k' data available for market_id {market_id}.\")\n",
    "        probabilities = market_k / market_k.sum()\n",
    "        \n",
    "        # Generate k values based on the distribution\n",
    "        k_i = np.random.choice(market_k.index, size=N, p=probabilities)\n",
    "        \n",
    "        # Combine all into a single DataFrame for this market\n",
    "        market_data = pd.DataFrame({\n",
    "            'market_ids': market_ids_i,\n",
    "            'weights': weights_i,\n",
    "            'k': k_i\n",
    "        })\n",
    "        \n",
    "        for i in range(11):\n",
    "            market_data[f'nodes{i}'] = nodes_i[:, i]\n",
    "        \n",
    "        # Append to the main list\n",
    "        agent_data_list.append(market_data)\n",
    "    \n",
    "    # Concatenate all market data\n",
    "    agent_data = pd.concat(agent_data_list, ignore_index=True)\n",
    "    \n",
    "    # Create dummy variables for k\n",
    "    agent_data = pd.concat([agent_data, pd.get_dummies(agent_data['k'], prefix='k')], axis=1)\n",
    "    \n",
    "    return agent_data\n",
    "\n",
    "\n",
    "# Create the agent_data DataFrame\n",
    "agent_data = create_agent_data(product_data, df)\n",
    "\n",
    "# Sort by market_ids for cleaner output\n",
    "agent_data = agent_data.sort_values('market_ids').reset_index(drop=True)\n",
    "agent_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up the problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(prices + x2 + x3 + x8 + x9 + x11 + x12, 1 + prices + x8 + x9 + x11 + x12)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#product formulation incorporates X1, X2 and X3. \n",
    "# X1: linear parameters of the utility function \n",
    "# X2: non-linear parameters of the utility function \n",
    "# X3: linear parameters of the cost function\n",
    "#X1_formulation = pyblp.Formulation('0 + prices ', absorb='C(x1) + C(x4) + C(x5) ') # when using absorb I got this error \"AbsorptionError: A fixed effect absorption procedure failed to properly absorb fixed effects. Consider configuring absorption options or choosing a different absorption method. For information about absorption options and defaults, refer to the PyHDFE package's documentation. Exception encountered: 'zero-size array to reduction operation maximum which has no identity'.\"\n",
    "K1 = 5 # vars without random coefficients \n",
    "K2 = len(car_type_dummies) + 2  # vars with random coefficients, the 1 is compulsory \n",
    "D = len(k_list) \n",
    "\n",
    "\n",
    "X1_formulation = pyblp.Formulation('0 + prices + C(x1) + x2 + x3 + C(x4) + C(x5) + '+ ' + '.join(car_type_dummies))\n",
    "X1_formulation = pyblp.Formulation('0 + prices + x2 + x3 + '+ ' + '.join(car_type_dummies)) #removed categorical variables to reduce the dimensionality of the problem. \n",
    "\n",
    "\n",
    "#X2_formulation = pyblp.Formulation('1 + prices + C(x6)') # the problem was that x6 was empty for the outside alternative\n",
    "X2_formulation = pyblp.Formulation('prices + ' + ' + '.join(car_type_dummies)\n",
    ")\n",
    "#X2_formulation = pyblp.Formulation('prices + x8 + x9 +  x11' )\n",
    "#X2_formulation = pyblp.Formulation('prices + x2 + x3' )\n",
    "product_formulations = (X1_formulation, X2_formulation ) \n",
    "product_formulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1 + k_0 + k_1 + k_2 + k_3 + k_4 + k_5 + k_6"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_formulation = pyblp.Formulation('1 + C(k)') #C(k) takes k as a categorical variable, if one wants to include a formula, for example income/price then one uses I(income/prices) \n",
    "\n",
    "agent_formulation = pyblp.Formulation('1 + '+ ' + '.join(k_list)) \n",
    "\n",
    "#k_list2 = k_list.copy() \n",
    "#k_list2.remove('k_0')\n",
    "#k_list2.remove('k_1')\n",
    "#k_list2.remove('k_2')\n",
    "#agent_formulation = pyblp.Formulation('1 + '+ ' + '.join(k_list2)) \n",
    "#agent_formulation = pyblp.Formulation('k_3 + k_4 + k_5 + k_6') \n",
    "\n",
    "agent_formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the problem ...\n",
      "Initialized the problem after 00:00:00.\n",
      "\n",
      "Dimensions:\n",
      "=======================================\n",
      " T    N      I     K1    K2    D    MD \n",
      "---  ----  -----  ----  ----  ---  ----\n",
      "217  2936  21700   7     6     8    6  \n",
      "=======================================\n",
      "\n",
      "Formulations:\n",
      "==================================================================================================================\n",
      "       Column Indices:           0         1          2          3          4          5          6          7    \n",
      "-----------------------------  ------  ---------  ---------  ---------  ---------  ---------  ---------  ---------\n",
      " X1: Linear Characteristics    prices     x2         x3         x8         x9         x11        x12              \n",
      "X2: Nonlinear Characteristics    1      prices       x8         x9         x11        x12                         \n",
      "       d: Demographics           1     k_0[True]  k_1[True]  k_2[True]  k_3[True]  k_4[True]  k_5[True]  k_6[True]\n",
      "==================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "problem = pyblp.Problem(product_formulations, product_data, agent_formulation, agent_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observations \n",
    "1. absorbed cause multicollinearity issues in the vars, be careful when using it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up micro-moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Purchases: 3894 Observations in All Markets"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_dataset = pyblp.MicroDataset(\n",
    "    name=\"Purchases\",\n",
    "    observations=len(df),\n",
    "    compute_weights=lambda t, p, a: np.ones((a.size, p.size)), # Equal weights for all observations \n",
    "    # if the microdata includes the outside good then it should be p.size + 1 \n",
    ")\n",
    "micro_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construct the micro statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_micro_statistics(df, k_list, car_type_dummies):\n",
    "    # Initialize lists to store results\n",
    "    moments = []\n",
    "    values = []\n",
    "    \n",
    "    # Loop over each k dummy variable\n",
    "    for k_var in k_list:\n",
    "        # Get observations where k_i = 1\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        k_mask = df[k_var] == 1\n",
    "        k_observations = df[k_mask]\n",
    "        \n",
    "        if len(k_observations) > 0:  # Only calculate if we have observations\n",
    "            # Calculate average price conditional on k_i = 1\n",
    "            avg_price_k = k_observations['prices'].mean()\n",
    "            moments.append(f'E[price | {k_var}=1]')\n",
    "            values.append(avg_price_k)\n",
    "            \n",
    "            # Loop over each car type dummy variable\n",
    "            for car_dummy in car_type_dummies:\n",
    "                # Calculate P(car_type=1 | k_i=1)\n",
    "                car_cond_prob = k_observations[car_dummy].mean()\n",
    "                moments.append(f'E[{car_dummy} | {k_var}=1]')\n",
    "                values.append(car_cond_prob)\n",
    "    \n",
    "    # Create the micro_statistics DataFrame\n",
    "    micro_statistics = pd.DataFrame({\n",
    "        'value': values\n",
    "    }, index=moments)\n",
    "    \n",
    "    return micro_statistics\n",
    "\n",
    "\n",
    "\n",
    "micro_statistics = create_micro_statistics(df, k_list, car_type_dummies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each micro- moment has two parts. Let's exemplify with the case of the average price paid by consumers of group k = {a} where imagine that we created dummies and we have k{a} =1 for that group\n",
    "\n",
    "1. The first part is the total numerator and is the total price paid by consumers of type {a}\n",
    "p_k{a}_num = pyblp.MicroPart(\n",
    "    name = 'E[p*( k{a} =1)]', \n",
    "    dataset = micro_dataset,\n",
    "    compute_values = lambda t, p, a: np.outer(a.demographics[:, z], np.r_[0, p.X2[:, w]])\n",
    ")\n",
    "\n",
    "In this case z: is the position of the variable  k{a} in the agent formulation. and w: is the position of the product characteristic in this case x8 in X2_formulation in product formulations. \n",
    "\n",
    "2. the second part is the numerator and counts how many consumers of type {a} are in our data. \n",
    "\n",
    "k{a}_den = pyblp.MicroPart(\n",
    "    name = 'E[ k{a} =1]', \n",
    "    dataset = micro_dataset,\n",
    "    compute_values = lambda t, p, a: np.outer(a.demographics[:, z], np.r_[0, p.X2[:, 0]])\n",
    ")\n",
    "In this case z: is the position of the variable  k{a} in the agent formulation. and w= 0 because we are summing and the only element of the summation is whether the consumer is type k{a} and in X2_formulation the first element is 1 hence we are just multiplying by 1 which has no effect. \n",
    "\n",
    "Note that we are creating the moments in the opposite way to the documentation because their moments are E(k\\type or price) whereas ours are E(type or price\\k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to map x variables to their corresponding X2 indices\n",
    "x_to_X2_index = {\n",
    "    'x8': 2,\n",
    "    'x9': 3,\n",
    "    'x10': 4,\n",
    "    'x11': 5,\n",
    "    'x12': 6\n",
    "}\n",
    "\n",
    "# Initialize dictionary to store all micro parts\n",
    "micro_parts = {}\n",
    "\n",
    " \n",
    "for k_idx, k in enumerate(k_list):\n",
    "    \n",
    "    #create de numerator (in the paper is v_{3i})\n",
    "    micro_parts[f'v_3{k}'] = pyblp.MicroPart(\n",
    "            name=f'E[(k={k_idx})]',\n",
    "            dataset=micro_dataset,\n",
    "            compute_values=lambda t, p, a: np.outer(\n",
    "                a.demographics[:, k_idx + 1], np.r_[0, p.X2[:, 0]])\n",
    "        )\n",
    "    \n",
    "    #create deenominator of price moment (in the paper is v_{2i})\n",
    "    micro_parts[f'v_2{k}'] = pyblp.MicroPart(\n",
    "            name=f'E[p*(k={k_idx})]',\n",
    "            dataset=micro_dataset,\n",
    "            compute_values=lambda t, p, a: np.outer(\n",
    "                a.demographics[:, k_idx + 1], np.r_[0, p.X2[:, 1]])\n",
    "        )\n",
    "\n",
    "    #create the numerators of type moments (in the paper is v_{1i\\lambda})\n",
    "    for x_var in car_type_dummies:\n",
    "        \n",
    "        X2_index = x_to_X2_index[x_var] # Get the corresponding X2 index\n",
    "            \n",
    "        micro_parts[f'v_3{k}{x_var}'] = pyblp.MicroPart(\n",
    "            name=f'E[({x_var}=1)*(k={k_idx})]',\n",
    "            dataset=micro_dataset,\n",
    "            compute_values=lambda t, p, a: np.outer(\n",
    "                a.demographics[:, k_idx + 1], np.r_[0, p.X2[:, X2_index]])\n",
    "        )\n",
    "\n",
    "# If you need them in separate variables instead of a dictionary:\n",
    "locals().update(micro_parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_ratio = lambda v: v[0] / v[1]\n",
    "compute_ratio_gradient = lambda v: [1 / v[1], -v[0] / v[1]**2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 k_0 18046864.603833865\n",
      "x8 0.18849840255591055\n",
      "x9 0.4952076677316294\n",
      "x11 0.10223642172523961\n",
      "x12 0.11182108626198083\n",
      "1 k_1 16679065.084867075\n",
      "x8 0.35991820040899797\n",
      "x9 0.48057259713701433\n",
      "x11 0.04703476482617587\n",
      "x12 0.07464212678936605\n",
      "2 k_2 19737623.44827586\n",
      "x8 0.5862068965517241\n",
      "x9 0.13793103448275862\n",
      "x11 0.1724137931034483\n",
      "x12 0.06896551724137931\n",
      "3 k_3 16443471.926708633\n",
      "x8 0.16052158273381295\n",
      "x9 0.6119604316546763\n",
      "x11 0.06115107913669065\n",
      "x12 0.09982014388489209\n",
      "4 k_4 17707223.056338027\n",
      "x8 0.3873239436619718\n",
      "x9 0.5\n",
      "x11 0.035211267605633804\n",
      "x12 0.06338028169014084\n",
      "5 k_5 17702596.98901099\n",
      "x8 0.2967032967032967\n",
      "x9 0.6703296703296703\n",
      "x11 0.01098901098901099\n",
      "x12 0.02197802197802198\n",
      "6 k_6 17528794.0\n",
      "x8 0.23076923076923078\n",
      "x9 0.5213675213675214\n",
      "x11 0.05982905982905983\n",
      "x12 0.1794871794871795\n"
     ]
    }
   ],
   "source": [
    "micro_moments = [] \n",
    "\n",
    "\n",
    "for k_idx, k in enumerate(k_list):\n",
    "    \n",
    "    price_statistic =  micro_statistics.loc[f'E[price | {k}=1]', 'value']\n",
    "    print(k_idx, k, price_statistic)\n",
    "    \n",
    "\n",
    "    price_moment = pyblp.MicroMoment(\n",
    "        name = f'E[price|k={k_idx}]',\n",
    "        value = price_statistic, \n",
    "        parts = [micro_parts[f'v_2{k}'], micro_parts[f'v_3{k}']], \n",
    "        compute_value = compute_ratio,\n",
    "        compute_gradient = compute_ratio_gradient, \n",
    "    )\n",
    "    micro_moments.append(price_moment)\n",
    "\n",
    "\n",
    "    for x_var in car_type_dummies: \n",
    "        type_statistic = micro_statistics.loc[f'E[{x_var} | {k}=1]', 'value']\n",
    "        print(x_var, type_statistic)\n",
    "\n",
    "\n",
    "        type_moment = pyblp.MicroMoment(\n",
    "            name = f'E[{x_var}|k={k_idx}]',\n",
    "            value = type_statistic, \n",
    "            parts = [micro_parts[f'v_3{k}{x_var}'], micro_parts[f'v_3{k}']], \n",
    "            compute_value = compute_ratio,\n",
    "            compute_gradient = compute_ratio_gradient, \n",
    "            )\n",
    "        micro_moments.append(type_moment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E[price|k=0]: +1.804686E+07 (E[p*(k=0)] on Purchases: 3894 Observations in All Markets; E[(k=0)] on Purchases: 3894 Observations in All Markets), E[x8|k=0]: +1.884984E-01 (E[(x8=1)*(k=0)] on Purchases: 3894 Observations in All Markets; E[(k=0)] on Purchases: 3894 Observations in All Markets), E[x9|k=0]: +4.952077E-01 (E[(x9=1)*(k=0)] on Purchases: 3894 Observations in All Markets; E[(k=0)] on Purchases: 3894 Observations in All Markets), E[x11|k=0]: +1.022364E-01 (E[(x11=1)*(k=0)] on Purchases: 3894 Observations in All Markets; E[(k=0)] on Purchases: 3894 Observations in All Markets), E[x12|k=0]: +1.118211E-01 (E[(x12=1)*(k=0)] on Purchases: 3894 Observations in All Markets; E[(k=0)] on Purchases: 3894 Observations in All Markets), E[price|k=1]: +1.667907E+07 (E[p*(k=1)] on Purchases: 3894 Observations in All Markets; E[(k=1)] on Purchases: 3894 Observations in All Markets), E[x8|k=1]: +3.599182E-01 (E[(x8=1)*(k=1)] on Purchases: 3894 Observations in All Markets; E[(k=1)] on Purchases: 3894 Observations in All Markets), E[x9|k=1]: +4.805726E-01 (E[(x9=1)*(k=1)] on Purchases: 3894 Observations in All Markets; E[(k=1)] on Purchases: 3894 Observations in All Markets), E[x11|k=1]: +4.703476E-02 (E[(x11=1)*(k=1)] on Purchases: 3894 Observations in All Markets; E[(k=1)] on Purchases: 3894 Observations in All Markets), E[x12|k=1]: +7.464213E-02 (E[(x12=1)*(k=1)] on Purchases: 3894 Observations in All Markets; E[(k=1)] on Purchases: 3894 Observations in All Markets), E[price|k=2]: +1.973762E+07 (E[p*(k=2)] on Purchases: 3894 Observations in All Markets; E[(k=2)] on Purchases: 3894 Observations in All Markets), E[x8|k=2]: +5.862069E-01 (E[(x8=1)*(k=2)] on Purchases: 3894 Observations in All Markets; E[(k=2)] on Purchases: 3894 Observations in All Markets), E[x9|k=2]: +1.379310E-01 (E[(x9=1)*(k=2)] on Purchases: 3894 Observations in All Markets; E[(k=2)] on Purchases: 3894 Observations in All Markets), E[x11|k=2]: +1.724138E-01 (E[(x11=1)*(k=2)] on Purchases: 3894 Observations in All Markets; E[(k=2)] on Purchases: 3894 Observations in All Markets), E[x12|k=2]: +6.896552E-02 (E[(x12=1)*(k=2)] on Purchases: 3894 Observations in All Markets; E[(k=2)] on Purchases: 3894 Observations in All Markets), E[price|k=3]: +1.644347E+07 (E[p*(k=3)] on Purchases: 3894 Observations in All Markets; E[(k=3)] on Purchases: 3894 Observations in All Markets), E[x8|k=3]: +1.605216E-01 (E[(x8=1)*(k=3)] on Purchases: 3894 Observations in All Markets; E[(k=3)] on Purchases: 3894 Observations in All Markets), E[x9|k=3]: +6.119604E-01 (E[(x9=1)*(k=3)] on Purchases: 3894 Observations in All Markets; E[(k=3)] on Purchases: 3894 Observations in All Markets), E[x11|k=3]: +6.115108E-02 (E[(x11=1)*(k=3)] on Purchases: 3894 Observations in All Markets; E[(k=3)] on Purchases: 3894 Observations in All Markets), E[x12|k=3]: +9.982014E-02 (E[(x12=1)*(k=3)] on Purchases: 3894 Observations in All Markets; E[(k=3)] on Purchases: 3894 Observations in All Markets), E[price|k=4]: +1.770722E+07 (E[p*(k=4)] on Purchases: 3894 Observations in All Markets; E[(k=4)] on Purchases: 3894 Observations in All Markets), E[x8|k=4]: +3.873239E-01 (E[(x8=1)*(k=4)] on Purchases: 3894 Observations in All Markets; E[(k=4)] on Purchases: 3894 Observations in All Markets), E[x9|k=4]: +5.000000E-01 (E[(x9=1)*(k=4)] on Purchases: 3894 Observations in All Markets; E[(k=4)] on Purchases: 3894 Observations in All Markets), E[x11|k=4]: +3.521127E-02 (E[(x11=1)*(k=4)] on Purchases: 3894 Observations in All Markets; E[(k=4)] on Purchases: 3894 Observations in All Markets), E[x12|k=4]: +6.338028E-02 (E[(x12=1)*(k=4)] on Purchases: 3894 Observations in All Markets; E[(k=4)] on Purchases: 3894 Observations in All Markets), E[price|k=5]: +1.770260E+07 (E[p*(k=5)] on Purchases: 3894 Observations in All Markets; E[(k=5)] on Purchases: 3894 Observations in All Markets), E[x8|k=5]: +2.967033E-01 (E[(x8=1)*(k=5)] on Purchases: 3894 Observations in All Markets; E[(k=5)] on Purchases: 3894 Observations in All Markets), E[x9|k=5]: +6.703297E-01 (E[(x9=1)*(k=5)] on Purchases: 3894 Observations in All Markets; E[(k=5)] on Purchases: 3894 Observations in All Markets), E[x11|k=5]: +1.098901E-02 (E[(x11=1)*(k=5)] on Purchases: 3894 Observations in All Markets; E[(k=5)] on Purchases: 3894 Observations in All Markets), E[x12|k=5]: +2.197802E-02 (E[(x12=1)*(k=5)] on Purchases: 3894 Observations in All Markets; E[(k=5)] on Purchases: 3894 Observations in All Markets), E[price|k=6]: +1.752879E+07 (E[p*(k=6)] on Purchases: 3894 Observations in All Markets; E[(k=6)] on Purchases: 3894 Observations in All Markets), E[x8|k=6]: +2.307692E-01 (E[(x8=1)*(k=6)] on Purchases: 3894 Observations in All Markets; E[(k=6)] on Purchases: 3894 Observations in All Markets), E[x9|k=6]: +5.213675E-01 (E[(x9=1)*(k=6)] on Purchases: 3894 Observations in All Markets; E[(k=6)] on Purchases: 3894 Observations in All Markets), E[x11|k=6]: +5.982906E-02 (E[(x11=1)*(k=6)] on Purchases: 3894 Observations in All Markets; E[(k=6)] on Purchases: 3894 Observations in All Markets), E[x12|k=6]: +1.794872E-01 (E[(x12=1)*(k=6)] on Purchases: 3894 Observations in All Markets; E[(k=6)] on Purchases: 3894 Observations in All Markets)]\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "print(micro_moments)\n",
    "print(len(micro_moments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solving the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the dimensions of sigma are the same as X2\n",
    "the dimensionn of pi is K2xD where in the tutorial K2 = dim(X2 formulation) and D is the number of demographic vars. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "K2 = 6\n",
    "D = 8\n",
    "initial_sigma = np.eye(K2) \n",
    "initial_pi = np.eye(K2, D)\n",
    "\n",
    "\n",
    "sigma_lb = np.zeros((K2, K2))\n",
    "sigma_up = np.eye(K2)*10 \n",
    "sigma_bounds = (sigma_lb, sigma_up)\n",
    "\n",
    "pi_lb = np.zeros((K2, D)) \n",
    "pi_up = np.eye(K2, D)*10\n",
    "pi_bounds = (pi_lb, pi_up)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving the problem ...\n",
      "\n",
      "Micro Moments:\n",
      "===============================================================================\n",
      "  Observed        Moment           Part         Dataset   Observations  Markets\n",
      "-------------  ------------  ----------------  ---------  ------------  -------\n",
      "+1.804686E+07  E[price|k=0]     E[p*(k=0)]     Purchases      3894        All  \n",
      "                                 E[(k=0)]      Purchases      3894        All  \n",
      "+1.884984E-01   E[x8|k=0]    E[(x8=1)*(k=0)]   Purchases      3894        All  \n",
      "                                 E[(k=0)]      Purchases      3894        All  \n",
      "+4.952077E-01   E[x9|k=0]    E[(x9=1)*(k=0)]   Purchases      3894        All  \n",
      "                                 E[(k=0)]      Purchases      3894        All  \n",
      "+1.022364E-01   E[x11|k=0]   E[(x11=1)*(k=0)]  Purchases      3894        All  \n",
      "                                 E[(k=0)]      Purchases      3894        All  \n",
      "+1.118211E-01   E[x12|k=0]   E[(x12=1)*(k=0)]  Purchases      3894        All  \n",
      "                                 E[(k=0)]      Purchases      3894        All  \n",
      "+1.667907E+07  E[price|k=1]     E[p*(k=1)]     Purchases      3894        All  \n",
      "                                 E[(k=1)]      Purchases      3894        All  \n",
      "+3.599182E-01   E[x8|k=1]    E[(x8=1)*(k=1)]   Purchases      3894        All  \n",
      "                                 E[(k=1)]      Purchases      3894        All  \n",
      "+4.805726E-01   E[x9|k=1]    E[(x9=1)*(k=1)]   Purchases      3894        All  \n",
      "                                 E[(k=1)]      Purchases      3894        All  \n",
      "+4.703476E-02   E[x11|k=1]   E[(x11=1)*(k=1)]  Purchases      3894        All  \n",
      "                                 E[(k=1)]      Purchases      3894        All  \n",
      "+7.464213E-02   E[x12|k=1]   E[(x12=1)*(k=1)]  Purchases      3894        All  \n",
      "                                 E[(k=1)]      Purchases      3894        All  \n",
      "+1.973762E+07  E[price|k=2]     E[p*(k=2)]     Purchases      3894        All  \n",
      "                                 E[(k=2)]      Purchases      3894        All  \n",
      "+5.862069E-01   E[x8|k=2]    E[(x8=1)*(k=2)]   Purchases      3894        All  \n",
      "                                 E[(k=2)]      Purchases      3894        All  \n",
      "+1.379310E-01   E[x9|k=2]    E[(x9=1)*(k=2)]   Purchases      3894        All  \n",
      "                                 E[(k=2)]      Purchases      3894        All  \n",
      "+1.724138E-01   E[x11|k=2]   E[(x11=1)*(k=2)]  Purchases      3894        All  \n",
      "                                 E[(k=2)]      Purchases      3894        All  \n",
      "+6.896552E-02   E[x12|k=2]   E[(x12=1)*(k=2)]  Purchases      3894        All  \n",
      "                                 E[(k=2)]      Purchases      3894        All  \n",
      "+1.644347E+07  E[price|k=3]     E[p*(k=3)]     Purchases      3894        All  \n",
      "                                 E[(k=3)]      Purchases      3894        All  \n",
      "+1.605216E-01   E[x8|k=3]    E[(x8=1)*(k=3)]   Purchases      3894        All  \n",
      "                                 E[(k=3)]      Purchases      3894        All  \n",
      "+6.119604E-01   E[x9|k=3]    E[(x9=1)*(k=3)]   Purchases      3894        All  \n",
      "                                 E[(k=3)]      Purchases      3894        All  \n",
      "+6.115108E-02   E[x11|k=3]   E[(x11=1)*(k=3)]  Purchases      3894        All  \n",
      "                                 E[(k=3)]      Purchases      3894        All  \n",
      "+9.982014E-02   E[x12|k=3]   E[(x12=1)*(k=3)]  Purchases      3894        All  \n",
      "                                 E[(k=3)]      Purchases      3894        All  \n",
      "+1.770722E+07  E[price|k=4]     E[p*(k=4)]     Purchases      3894        All  \n",
      "                                 E[(k=4)]      Purchases      3894        All  \n",
      "+3.873239E-01   E[x8|k=4]    E[(x8=1)*(k=4)]   Purchases      3894        All  \n",
      "                                 E[(k=4)]      Purchases      3894        All  \n",
      "+5.000000E-01   E[x9|k=4]    E[(x9=1)*(k=4)]   Purchases      3894        All  \n",
      "                                 E[(k=4)]      Purchases      3894        All  \n",
      "+3.521127E-02   E[x11|k=4]   E[(x11=1)*(k=4)]  Purchases      3894        All  \n",
      "                                 E[(k=4)]      Purchases      3894        All  \n",
      "+6.338028E-02   E[x12|k=4]   E[(x12=1)*(k=4)]  Purchases      3894        All  \n",
      "                                 E[(k=4)]      Purchases      3894        All  \n",
      "+1.770260E+07  E[price|k=5]     E[p*(k=5)]     Purchases      3894        All  \n",
      "                                 E[(k=5)]      Purchases      3894        All  \n",
      "+2.967033E-01   E[x8|k=5]    E[(x8=1)*(k=5)]   Purchases      3894        All  \n",
      "                                 E[(k=5)]      Purchases      3894        All  \n",
      "+6.703297E-01   E[x9|k=5]    E[(x9=1)*(k=5)]   Purchases      3894        All  \n",
      "                                 E[(k=5)]      Purchases      3894        All  \n",
      "+1.098901E-02   E[x11|k=5]   E[(x11=1)*(k=5)]  Purchases      3894        All  \n",
      "                                 E[(k=5)]      Purchases      3894        All  \n",
      "+2.197802E-02   E[x12|k=5]   E[(x12=1)*(k=5)]  Purchases      3894        All  \n",
      "                                 E[(k=5)]      Purchases      3894        All  \n",
      "+1.752879E+07  E[price|k=6]     E[p*(k=6)]     Purchases      3894        All  \n",
      "                                 E[(k=6)]      Purchases      3894        All  \n",
      "+2.307692E-01   E[x8|k=6]    E[(x8=1)*(k=6)]   Purchases      3894        All  \n",
      "                                 E[(k=6)]      Purchases      3894        All  \n",
      "+5.213675E-01   E[x9|k=6]    E[(x9=1)*(k=6)]   Purchases      3894        All  \n",
      "                                 E[(k=6)]      Purchases      3894        All  \n",
      "+5.982906E-02   E[x11|k=6]   E[(x11=1)*(k=6)]  Purchases      3894        All  \n",
      "                                 E[(k=6)]      Purchases      3894        All  \n",
      "+1.794872E-01   E[x12|k=6]   E[(x12=1)*(k=6)]  Purchases      3894        All  \n",
      "                                 E[(k=6)]      Purchases      3894        All  \n",
      "===============================================================================\n",
      "\n",
      "Nonlinear Coefficient Initial Values:\n",
      "===================================================================================================================================================================================================================================\n",
      "Sigma:        1           prices           x8             x9             x11            x12       |   Pi:          1          k_0[True]      k_1[True]      k_2[True]      k_3[True]      k_4[True]      k_5[True]      k_6[True]  \n",
      "------  -------------  -------------  -------------  -------------  -------------  -------------  |  ------  -------------  -------------  -------------  -------------  -------------  -------------  -------------  -------------\n",
      "  1     +1.000000E+00                                                                             |    1     +1.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00\n",
      "prices  +0.000000E+00  +1.000000E+00                                                              |  prices  +0.000000E+00  +1.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00\n",
      "  x8    +0.000000E+00  +0.000000E+00  +1.000000E+00                                               |    x8    +0.000000E+00  +0.000000E+00  +1.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00\n",
      "  x9    +0.000000E+00  +0.000000E+00  +0.000000E+00  +1.000000E+00                                |    x9    +0.000000E+00  +0.000000E+00  +0.000000E+00  +1.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00\n",
      " x11    +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +1.000000E+00                 |   x11    +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +1.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00\n",
      " x12    +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +1.000000E+00  |   x12    +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +1.000000E+00  +0.000000E+00  +0.000000E+00\n",
      "===================================================================================================================================================================================================================================\n",
      "\n",
      "Nonlinear Coefficient Lower Bounds:\n",
      "===================================================================================================================================================================================================================================\n",
      "Sigma:        1           prices           x8             x9             x11            x12       |   Pi:          1          k_0[True]      k_1[True]      k_2[True]      k_3[True]      k_4[True]      k_5[True]      k_6[True]  \n",
      "------  -------------  -------------  -------------  -------------  -------------  -------------  |  ------  -------------  -------------  -------------  -------------  -------------  -------------  -------------  -------------\n",
      "  1         -INF                                                                                  |    1         -INF       +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00\n",
      "prices  +0.000000E+00      -INF                                                                   |  prices  +0.000000E+00      -INF       +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00\n",
      "  x8    +0.000000E+00  +0.000000E+00      -INF                                                    |    x8    +0.000000E+00  +0.000000E+00      -INF       +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00\n",
      "  x9    +0.000000E+00  +0.000000E+00  +0.000000E+00      -INF                                     |    x9    +0.000000E+00  +0.000000E+00  +0.000000E+00      -INF       +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00\n",
      " x11    +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00      -INF                      |   x11    +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00      -INF       +0.000000E+00  +0.000000E+00  +0.000000E+00\n",
      " x12    +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00      -INF       |   x12    +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00      -INF       +0.000000E+00  +0.000000E+00\n",
      "===================================================================================================================================================================================================================================\n",
      "\n",
      "Nonlinear Coefficient Upper Bounds:\n",
      "===================================================================================================================================================================================================================================\n",
      "Sigma:        1           prices           x8             x9             x11            x12       |   Pi:          1          k_0[True]      k_1[True]      k_2[True]      k_3[True]      k_4[True]      k_5[True]      k_6[True]  \n",
      "------  -------------  -------------  -------------  -------------  -------------  -------------  |  ------  -------------  -------------  -------------  -------------  -------------  -------------  -------------  -------------\n",
      "  1         +INF                                                                                  |    1         +INF       +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00\n",
      "prices  +0.000000E+00      +INF                                                                   |  prices  +0.000000E+00      +INF       +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00\n",
      "  x8    +0.000000E+00  +0.000000E+00      +INF                                                    |    x8    +0.000000E+00  +0.000000E+00      +INF       +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00\n",
      "  x9    +0.000000E+00  +0.000000E+00  +0.000000E+00      +INF                                     |    x9    +0.000000E+00  +0.000000E+00  +0.000000E+00      +INF       +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00\n",
      " x11    +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00      +INF                      |   x11    +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00      +INF       +0.000000E+00  +0.000000E+00  +0.000000E+00\n",
      " x12    +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00      +INF       |   x12    +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00  +0.000000E+00      +INF       +0.000000E+00  +0.000000E+00\n",
      "===================================================================================================================================================================================================================================\n",
      "\n",
      "Updating starting values for the weighting matrix and delta ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "In market 0, micro moment part 'E[p*(k=0)] on Purchases: 3894 Observations in All Markets' returned an array of shape (100, 8) from compute_values, which is not (100, 7), the shape of the array returned by its dataset's compute_weights.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[343], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mproblem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_sigma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msigma_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_pi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpi_bounds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpi_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpyblp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOptimization\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbfgs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpyblp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIteration\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msquarem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43matol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-13\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmicro_moments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmicro_moments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m results\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyblp\\economies\\problem.py:715\u001b[0m, in \u001b[0;36mProblemEconomy.solve\u001b[1;34m(self, sigma, pi, rho, beta, gamma, sigma_bounds, pi_bounds, rho_bounds, beta_bounds, gamma_bounds, delta, method, initial_update, optimization, scale_objective, check_optimality, finite_differences, error_behavior, error_punishment, delta_behavior, iteration, fp_type, shares_bounds, costs_bounds, W, center_moments, W_type, se_type, covariance_moments_mean, micro_moments, micro_sample_covariances, resample_agent_data)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    714\u001b[0m     output(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimating standard errors ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 715\u001b[0m final_progress \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_step_progress\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_gradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_hessian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_micro_covariances\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetect_micro_collinearity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_simulation_covariances\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    719\u001b[0m iteration_stats\u001b[38;5;241m.\u001b[39mappend(final_progress\u001b[38;5;241m.\u001b[39miteration_stats)\n\u001b[0;32m    720\u001b[0m optimization_stats\u001b[38;5;241m.\u001b[39mevaluations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyblp\\economies\\problem.py:839\u001b[0m, in \u001b[0;36mProblemEconomy._compute_progress\u001b[1;34m(self, parameters, moments, iv, W, scale_objective, error_behavior, error_punishment, delta_behavior, iteration, fp_type, shares_bounds, costs_bounds, finite_differences, covariance_moments_mean, resample_agent_data, theta, progress, compute_gradient, compute_hessian, compute_micro_covariances, detect_micro_collinearity, compute_simulation_covariances, agents_override)\u001b[0m\n\u001b[0;32m    837\u001b[0m parts_collinearity_candidate_values: Dict[Hashable, Dict[MicroDataset, Array]] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    838\u001b[0m generator \u001b[38;5;241m=\u001b[39m generate_items(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_market_ids, market_factory, ProblemMarket\u001b[38;5;241m.\u001b[39msolve)\n\u001b[1;32m--> 839\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, generated_t \u001b[38;5;129;01min\u001b[39;00m generator:\n\u001b[0;32m    840\u001b[0m     (\n\u001b[0;32m    841\u001b[0m         delta_t, xi_jacobian_t, parts_numerator_t, parts_denominator_t, parts_numerator_jacobian_t,\n\u001b[0;32m    842\u001b[0m         parts_denominator_jacobian_t, parts_covariances_numerator_t, weights_mapping_t, values_mapping_t,\n\u001b[0;32m    843\u001b[0m         clipped_shares_t, iteration_stats_t, tilde_costs_t, omega_jacobian_t, clipped_costs_t, errors_t\n\u001b[0;32m    844\u001b[0m     ) \u001b[38;5;241m=\u001b[39m generated_t\n\u001b[0;32m    846\u001b[0m     delta[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_product_market_indices[t]] \u001b[38;5;241m=\u001b[39m delta_t\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyblp\\utilities\\basics.py:164\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate (key, method(*factory(key))) tuples for each key. The first element returned by factory is an instance\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03mof the class to which method is attached. If a process pool has been initialized, use multiprocessing; otherwise,\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03muse serial processing.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mgenerate_items_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pool\u001b[38;5;241m.\u001b[39mimap_unordered(generate_items_worker, ((k, factory(k), method) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyblp\\utilities\\basics.py:173\u001b[0m, in \u001b[0;36mgenerate_items_worker\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call the specified method of a class instance with any additional arguments. Return the associated key along with\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03mthe returned object.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    172\u001b[0m key, (instance, \u001b[38;5;241m*\u001b[39mmethod_args), method \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m key, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyblp\\utilities\\basics.py:665\u001b[0m, in \u001b[0;36mNumericalErrorHandler.__call__.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m, over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m, under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    664\u001b[0m     np\u001b[38;5;241m.\u001b[39mseterrcall(detector)\n\u001b[1;32m--> 665\u001b[0m     returned \u001b[38;5;241m=\u001b[39m \u001b[43mdecorated\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detector\u001b[38;5;241m.\u001b[39mdetected \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    667\u001b[0m     returned[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(detector\u001b[38;5;241m.\u001b[39mdetected)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyblp\\markets\\problem_market.py:93\u001b[0m, in \u001b[0;36mProblemMarket.solve\u001b[1;34m(self, delta, last_delta, last_tilde_costs, moments, iteration, fp_type, shares_bounds, costs_bounds, compute_jacobians, compute_micro_covariances, keep_micro_mappings)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m probabilities \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     (\n\u001b[0;32m     90\u001b[0m         parts_numerator, parts_denominator, parts_numerator_jacobian, parts_denominator_jacobian,\n\u001b[0;32m     91\u001b[0m         parts_covariances_numerator, weights_mapping, values_mapping, micro_errors\n\u001b[0;32m     92\u001b[0m     ) \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 93\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafely_compute_micro_contributions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmoments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_delta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobabilities_tangent_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxi_jacobian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_jacobians\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompute_micro_covariances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_micro_mappings\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     98\u001b[0m     errors\u001b[38;5;241m.\u001b[39mextend(micro_errors)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# only compute supply side contributions if there is a supply side\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyblp\\utilities\\basics.py:665\u001b[0m, in \u001b[0;36mNumericalErrorHandler.__call__.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m, over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m, under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    664\u001b[0m     np\u001b[38;5;241m.\u001b[39mseterrcall(detector)\n\u001b[1;32m--> 665\u001b[0m     returned \u001b[38;5;241m=\u001b[39m \u001b[43mdecorated\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detector\u001b[38;5;241m.\u001b[39mdetected \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    667\u001b[0m     returned[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(detector\u001b[38;5;241m.\u001b[39mdetected)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyblp\\markets\\problem_market.py:171\u001b[0m, in \u001b[0;36mProblemMarket.safely_compute_micro_contributions\u001b[1;34m(self, moments, delta, probabilities, probabilities_tangent_mapping, xi_jacobian, compute_jacobians, compute_covariances, keep_mappings)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute micro moment part contributions, handling any numerical errors.\"\"\"\u001b[39;00m\n\u001b[0;32m    166\u001b[0m errors: List[Error] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    167\u001b[0m (\n\u001b[0;32m    168\u001b[0m     parts_numerator, parts_denominator, parts_numerator_jacobian, parts_denominator_jacobian,\n\u001b[0;32m    169\u001b[0m     parts_covariances_numerator, weights_mapping, values_mapping\n\u001b[0;32m    170\u001b[0m ) \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_micro_contributions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmoments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobabilities_tangent_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxi_jacobian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_jacobians\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompute_covariances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_mappings\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m )\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    177\u001b[0m     parts_numerator, parts_denominator, parts_numerator_jacobian, parts_denominator_jacobian,\n\u001b[0;32m    178\u001b[0m     parts_covariances_numerator, weights_mapping, values_mapping, errors\n\u001b[0;32m    179\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyblp\\markets\\market.py:1842\u001b[0m, in \u001b[0;36mMarket.compute_micro_contributions\u001b[1;34m(self, moments, delta, probabilities, probabilities_tangent_mapping, xi_jacobian, compute_jacobians, compute_covariances, keep_mappings)\u001b[0m\n\u001b[0;32m   1840\u001b[0m \u001b[38;5;66;03m# compute and validate moment values\u001b[39;00m\n\u001b[0;32m   1841\u001b[0m weights_chunk \u001b[38;5;241m=\u001b[39m weights_mapping_chunk[dataset]\n\u001b[1;32m-> 1842\u001b[0m values_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_micro_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1844\u001b[0m \u001b[38;5;66;03m# cache values if necessary\u001b[39;00m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_mappings:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyblp\\markets\\market.py:1423\u001b[0m, in \u001b[0;36mMarket.compute_micro_values\u001b[1;34m(self, part, weights, agent_indices)\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexception\u001b[39;00m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m weights\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m-> 1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1424\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn market \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, micro moment part \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m returned an array of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1425\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute_values, which is not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, the shape of the array returned by its \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1426\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms compute_weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1427\u001b[0m     )\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[1;31mValueError\u001b[0m: In market 0, micro moment part 'E[p*(k=0)] on Purchases: 3894 Observations in All Markets' returned an array of shape (100, 8) from compute_values, which is not (100, 7), the shape of the array returned by its dataset's compute_weights."
     ]
    }
   ],
   "source": [
    "results = problem.solve(\n",
    "    sigma=initial_sigma,\n",
    "    sigma_bounds=sigma_bounds,\n",
    "    pi=initial_pi,\n",
    "    pi_bounds = pi_bounds,\n",
    "    optimization=pyblp.Optimization('bfgs', {'gtol': 1e-4}),\n",
    "    iteration=pyblp.Iteration('squarem', {'atol': 1e-13}),\n",
    "    micro_moments=micro_moments,\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0x1a2bedc2b90>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(product_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0x1a2e4222050>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
